{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6458470",
   "metadata": {},
   "source": [
    "# VibeVoice Audio Creation Notebook\n",
    "\n",
    "This notebook is designed for creating MP3 audio content using Microsoft's VibeVoice package from a Markdown file or a chapter in an epub file. It is intended to be executed on Google Colab with A100 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae94224",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ebooklib soundfile torch litellm pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34179b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/microsoft/VibeVoice.git\n",
    "!cd VibeVoice/ && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import ebooklib\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from ebooklib import epub\n",
    "from google.colab import files, drive, userdata\n",
    "from litellm import completion\n",
    "from pydub import AudioSegment\n",
    "from vibevoice.modular.modeling_vibevoice_inference import (\n",
    "    VibeVoiceForConditionalGenerationInference,\n",
    ")\n",
    "from vibevoice.processor.vibevoice_processor import VibeVoiceProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac0a44",
   "metadata": {},
   "source": [
    "**Note**: In case of the `ModuleNotFoundError: No module named 'vibevoice'` error even after a successful installation of the package, the workaround is to click on `Run` in the menu bar and then select `Restart session and run all`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8c538",
   "metadata": {},
   "source": [
    "## Setup Requirements\n",
    "\n",
    "Before proceeding with audio generation, ensure the following setup is complete:\n",
    "\n",
    "### 1. Mount Google Drive\n",
    "Execute the cell below to mount your Google Drive, which will be used for storing outputs and accessing voice samples.\n",
    "\n",
    "### 2. Voice Samples Directory\n",
    "Create a directory, say at `/content/drive/MyDrive/VibeVoice/voices/`, and upload the voice sample files found in the [repository](https://github.com/microsoft/VibeVoice/tree/main/demo/voices). These voice samples are required for VibeVoice to generate audio with the specified speaker characteristics.\n",
    "\n",
    "### 3. Add secrets to Colab\n",
    "Add the OpenAI API key to Colab by including it as a secret with the name `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480dac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6c540",
   "metadata": {},
   "source": [
    "## 1. [Class] Read and Parse Data\n",
    "- Read Markdown or epub files as input\n",
    "- Filter and select the desired chapter from an epub file\n",
    "- Check for the presence of speakers in the text\n",
    "- If only a single speaker is present, prepend each line with \"Speaker 1: \" for clarity\n",
    "- Use GPT-5 Nano to format the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9fe62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VibeVoiceDataParser:\n",
    "    def __init__(\n",
    "        self, file_path: str, chapter_id: str | None = None, use_gpt: bool = True\n",
    "    ) -> None:\n",
    "        self.file_path = file_path\n",
    "        self.chapter_id = chapter_id\n",
    "        self.use_gpt = use_gpt\n",
    "        self.text = \"\"\n",
    "        self.ext = Path(file_path).suffix.lower()\n",
    "\n",
    "    def read(self) -> str:\n",
    "        if self.ext == \".md\":\n",
    "            self.text = self._read_md()\n",
    "        elif self.ext == \".epub\" and epub:\n",
    "            self.text = self._read_epub()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type or missing epublib.\")\n",
    "        return self.text\n",
    "\n",
    "    def _read_md(self) -> str:\n",
    "        with open(self.file_path, encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    def _read_epub(self) -> str:\n",
    "        book = epub.read_epub(self.file_path)\n",
    "        items = [i for i in book.get_items() if i.get_type() == ebooklib.ITEM_DOCUMENT]\n",
    "        if self.chapter_id is not None:\n",
    "            for item in items:\n",
    "                if getattr(item, \"id\", None) == self.chapter_id:\n",
    "                    return item.get_content().decode(\"utf-8\")\n",
    "            raise ValueError(f\"Chapter ID '{self.chapter_id}' not found\")\n",
    "        return \"\\n\".join(i.get_content().decode(\"utf-8\") for i in items)\n",
    "\n",
    "    def list_chapter_ids(self) -> list[str]:\n",
    "        \"\"\"List available chapters in EPUB file\"\"\"\n",
    "        if self.ext != \".epub\":\n",
    "            raise ValueError(\"Chapter listing is only available for EPUB files\")\n",
    "\n",
    "        book = epub.read_epub(self.file_path)\n",
    "        items = [i for i in book.get_items() if i.get_type() == ebooklib.ITEM_DOCUMENT]\n",
    "        ids = [str(getattr(item, \"id\", f\"{i}\")) for i, item in enumerate(items)]\n",
    "        return ids\n",
    "\n",
    "    def parse(self) -> str:\n",
    "        if self.use_gpt:\n",
    "            formatted = self._format_with_gpt(self.text)\n",
    "            return self._prepend_speaker(formatted)\n",
    "        else:\n",
    "            return self._prepend_speaker(self.text)\n",
    "\n",
    "    def _prepend_speaker(self, txt: str) -> str:\n",
    "        lines = txt.splitlines()\n",
    "        out = []\n",
    "        for line in lines:\n",
    "            if line.strip() and not line.strip().startswith(\"Speaker\"):\n",
    "                out.append(f\"Speaker 1: {line}\")\n",
    "            else:\n",
    "                out.append(line)\n",
    "        return \"\\n\".join(out)\n",
    "\n",
    "    def _format_with_gpt(self, txt: str) -> str:\n",
    "        prompt = (\n",
    "            \"You are a text formatting assistant for audio synthesis. \"\n",
    "            \"Given the following text, perform these steps: \"\n",
    "            \"1. If the text is a Markdown file and contains metadata in YAML front matter (e.g., lines between ---), extract the title and author fields, and replace the metadata block with '<title> by <author>' at the top of the text. \"\n",
    "            \"2. If the text contains HTML or XML, convert it to Markdown first.\"\n",
    "            \"2. Remove all Markdown and HTML formatting (bold, italics, tags, etc). \"\n",
    "            \"3. Convert unordered lists (-, *, +) to ordered lists with numbers. \"\n",
    "            \"4. Replace Markdown headings (#, ##, etc) with hierarchical numbers (e.g., # becomes 1, ## becomes 1.1), but do not add numbers if already present. \"\n",
    "            \"5. Do NOT add numbers to lines that are not part of a list or a heading.\"\n",
    "            \"6. If the text is from an EPUB and a chapter number is provided, only format that chapter. \"\n",
    "            \"7. For any ordered list, including in headings, use the format '1. ', '1.1. ', etc.\"\n",
    "            \"8. In case of any URLs in the Markdown text, remove the link and only retain the text.\\n\"\n",
    "            \"Return only the formatted text, no explanations.\\n\\nText:\\n\" + txt\n",
    "        )\n",
    "        response = completion(\n",
    "            model=\"gpt-5-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            reasoning_effort=\"minimal\",\n",
    "            max_completion_tokens=16384,\n",
    "        )\n",
    "\n",
    "        print(f\"Cost: ${response._hidden_params['response_cost']}\")\n",
    "        print(f\"Input tokens: {response.usage.prompt_tokens}\")\n",
    "        print(f\"Output tokens: {response.usage.completion_tokens}\")\n",
    "\n",
    "        formatted = response.choices[0].message.content\n",
    "        return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e0512",
   "metadata": {},
   "source": [
    "## Format Data\n",
    "\n",
    "In EPUB files, content is divided into separate chunks (cover, preface, introduction, chapters) with unique IDs that may not correspond to chapter names or numbers. Use `parser.list_chapter_ids()` to see available chapters and map IDs to your desired chapter before selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e856f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['titlepage',\n",
       " 'IFC.htm',\n",
       " 'title.htm',\n",
       " 'copyright.htm',\n",
       " 'dedication.htm',\n",
       " 'ToC.htm',\n",
       " 'FM.htm',\n",
       " 'x01.htm',\n",
       " 'x02.htm',\n",
       " 'x03.htm',\n",
       " 'x04.htm',\n",
       " 'x05.htm',\n",
       " 'x06.htm',\n",
       " 'x07.htm',\n",
       " 'x08.htm',\n",
       " 'A.htm',\n",
       " 'B.htm',\n",
       " 'C.htm',\n",
       " 'index.htm',\n",
       " 'IBC.htm']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"<path_to_your_epub_file>\"\n",
    "parser = VibeVoiceDataParser(file_path, chapter_id=\"x01.htm\")\n",
    "# parser.list_chapter_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f9383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m22:47:30 - LiteLLM:WARNING\u001b[0m: utils.py:528 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'max_completion_tokens': 16384, 'reasoning_effort': 'minimal', 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-CBog6D8nCXaVCPHltOGpztdeqN4p0\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"1 Optimizing systems by experiment\\n\\nThis chapter covers\\n\\n1. Optimizing an engineered system\\n2. Exploring what experiments are\\n3. Learning why experiments are uniquely valuable\\n\\nThe past 20 years have seen a surge in interest in the development of experimental methods used to measure and improve engineered systems, such as web products, automated trading systems, and software infrastructure. Experimental methods have become more automated and more efficient. They have scaled up to large systems like search engines or social media sites. These methods generate continuous, automated performance improvement of live production systems.\\n\\nUsing these experimental methods, engineers measure the business impact of the changes they make to their systems and determine the optimal settings under which to run them. We call this process experimental optimization.\\n\\nThis book teaches several experimental optimization methods used by engineers working in trading and technology. We\\u2019ll discuss systems built by three specific types of engineers:\\n\\n1. Machine learning engineers\\n2. Quantitative traders (\\u201cquants\\u201d)\\n3. Software engineers\\n\\nMachine learning engineers often work on web products like search engines, recommender systems, and ad placement systems. Quants build automated trading systems. Software engineers build infrastructure and tooling such as web servers, compilers, and event processing systems.\\n\\nThese engineers follow a common process, or workflow, that is an endless loop of steady system improvement. Figure 1.1 shows this common workflow.\\n\\nFigure 1.1 Common engineering workflow. (1) A new idea is first implemented as a code change to the system. (2) Typically, some offline evaluation is performed that rejects ideas that are expected to negatively impact business metrics. (3) The change is pushed into the production system, and business metrics are measured there, online. Accepted changes become permanent parts of the system. The whole workflow repeats, creating reliable, continuous improvement of the system.\\n\\nThe common workflow creates progressive improvement of an engineered system. An individual or a team generates ideas that they expect will improve the system, and they pass each idea through the workflow. Good ideas are accepted into the system, and bad ideas are rejected:\\n\\n1. Implement change\\u2014First, an engineer implements an idea as a code change, an update to the system\\u2019s software. In this stage, the code is subjected to typical software engineering quality controls, like code review and unit testing. If it passes all tests, it moves on to the next stage.\\n2. Evaluate offline\\u2014The business impact of the code change is evaluated offline, away from the production system. This evaluation typically uses data previously logged by the production system to produce rough estimates of business metrics such as revenue or the expected number of clicks on an advertisement. If these estimates show that applying this code change to the production system would worsen business metrics, then the code change is rejected. Otherwise, it is passed to the final stage.\\n3. Measure online\\u2014The change is pushed into production, where its impact on business metrics is measured. The code change might require some configuration\\u2014the setting of numerical parameters or Boolean flags. If so, the engineer will measure business metrics for multiple configurations to determine which is best. If no improvements to business metrics can be made by applying (and configuring) this code change, then the code change is rejected. Otherwise, the change is made permanent and the system improves.\\n\\nThis book deals with the final stage, \\u201cmeasure online.\\u201d In this stage, you run an experiment on the live production system. Experimentation is valuable because it produces a measurement from the real system, which is information you couldn\\u2019t get any other way. But experimentation on a live system takes time. Some experiments take days or weeks to run. And it is not without risk. When you run an experiment, you may lose money, alienate users, or generate bad press or social media chatter as users notice and complain about the changes you\\u2019re making to your system. Therefore, you need to take measurements as quickly and precisely as possible to minimize the ill effects of ideas\\u2014call them costs for brevity\\u2014that don\\u2019t work and to take maximal advantage of ones that do.\\n\\nTo extract the most value from a new bit of code, you need to configure it optimally. You could liken the process of finding the best configuration to tuning an old AM or FM radio or tuning a guitar string. You typically turn a knob up and down and listen to see whether you\\u2019re getting good results. Set the knob too high or too low and your radio will be noisy, or your guitar will be sharp or flat. So it is with code configuration parameters (often referred to as knobs in code your author has read). You want them set to just the right values to give maximal business impact\\u2014whether that\\u2019s revenue or clicks or some other metric. Note that the need to run costly experiments is what specifies experimental optimization methods as a subset of optimization methods more generally.\\n\\nIn this chapter, we\\u2019ll discuss engineering workflows for each of the engineer types listed earlier\\u2014machine learning engineer (MLE), quant, and software engineer (SWE). We\\u2019ll see what kinds of systems they work on, the business metrics they measure, and how each stage of the generic workflow is implemented.\\n\\nIn your organization, you might hear of alternative ways of evaluating changes to a system. Common suggestions are domain knowledge, model-based estimates, and simulation. We\\u2019ll discuss the reason why these tools, while valuable, can\\u2019t substitute for an experimental measurement.\\n\\n1.1 Examples of engineering workflows\\n\\nWhile the engineers listed earlier may work in different domains, their overall workflows are similar. Their workflows can be seen as specific cases of the common engineering workflow we described in figure 1.1: implement change, evaluate offline, measure online. Let\\u2019s look in detail at an example workflow for an MLE, for a quant, and for an SWE.\\n\\n1.1.1 Machine learning engineer\\u2019s workflow\\n\\nImagine an MLE who works on a web-based news site. Their workflow might look like figure 1.2.\\n\\nFigure 1.2 Example workflow for a machine learning engineer building a news-based website. The site contains an ML component that predicts clicks on news articles. (1) The MLE fits a new predictor. (2) An estimate of ad revenue from the new predictor is made using logs of user clicks and ad rates. (3) The new predictor is deployed to production and actual ad revenue is measured. If it improves ad revenue, then it is accepted into the system.\\n\\nThe key machine learning component of the website is a predictor model that predicts which news articles a user will click on. The predictor might take as input many features, such as information about the user\\u2019s demographics, the user\\u2019s previous activity on the website, and information about the news article\\u2019s title or its content. The predictor\\u2019s output will be an estimate of the probability that a specific user will click on a given news article. The website could use those predictions to rank and sort news articles on a headlines-summary page hoping to put more appealing news higher up on the page.\\n\\nFigure 1.2 depicts the workflow for this system. When the MLE comes up with an idea to improve the predictor\\u2014a new feature or a new model type\\u2014the idea is subjected to the workflow:\\n\\n1. Implement change\\u2014The MLE fits the new predictor to logged data. If it produces better predictions on the logged data than the previous predictor, it passes to the next stage.\\n2. Evaluate offline\\u2014The business goal is to increase revenue from ads that run on the website, not simply to improve click predictions. Translating improved predictions into improved revenue is not straightforward, but methods exist that give useful estimates for some systems. If the estimates do not look very bad, the predictor will pass on to the next stage.\\n3. Measure online\\u2014The MLE deploys the predictor to production, and real users see their headlines ranked with it. The MLE measures the ad revenue and compares it to the ad revenue produced by the old predictor. If the new predictor improves ad revenue, then it is accepted into the system.\\n\\nA news-based website may have many other components besides a click predictor. Each of those components would be exposed to the same workflow as the predictor, ensuring that the system steadily produces more ad revenue.\\n\\nMLEs work on many kinds of systems. Sorting news headlines by click probability is an example of a broader class of system called a recommender system. Recommender systems are used to rank videos, music, social media posts, consumer goods, and more. Search engines are a similar ML system, in that they may rank search results specifically for the user. Targeted advertising, which chooses ads specifically for the user, is another type of MLE system. Now let\\u2019s turn to finance and see how quants follow the same workflow pattern.\\n\\n1.1.2 Quantitative trader\\u2019s workflow\\n\\nA quant\\u2019s workflow is very similar to the MLE\\u2019s workflow. Only the details change. There\\u2019s a different prediction to be made, for example. See figure 1.3.\\n\\nFigure 1.3 Example workflow for a quant designing an automated trading strategy. The strategy contains a price-change predictor. (1) The quant produces a new predictor. (2) Profit and risk estimates come from a simulation using historical market data. (3) Live trading measures the true profit and risk. If the new predictor increases profit and/or reduces risk, then it is accepted into the system.\\n\\nThis quant is building an automated trading strategy. It is a piece of software that issues BUY and SELL orders to an exchange hoping to, as they say, buy low and sell high. A key component is a model that predicts change in the price of the financial instrument (e.g., a stock) being traded. If the price is predicted to increase, it\\u2019s a good time to issue a BUY order. Similarly, if the price is predicted to decrease, it\\u2019s a good time to SELL. The business metric for this system is profit. But it\\u2019s also risk. Quants want both higher profit and lower risk. It is not uncommon (in practice, it\\u2019s the norm) to be concerned with more than one business metric when optimizing a system. Chapter 7, section 3 will discuss this important practical point in detail.\\n\\nFigure 1.3 shows the quant\\u2019s workflow. Changes to the trading strategy pass through these stages:\\n\\n1. Implement change\\u2014The quant fits the new price-change predictor to historical market data and verifies that it produces better predictions than the previous predictor.\\n2. Evaluate offline\\u2014Better price predictions do not guarantee higher profits (or lower risk). The full trading strategy\\u2014predictor, BUY/SELL orders, and so on\\u2014is run through a simulation (also called a backtest) on historical market data. The simulation generates predictions and mimics buying and selling to estimate profit and risk. Sufficient improvement in the strategy will allow the predictor to pass to the next stage.\\n3. Measure online\\u2014The predictor is deployed to live trading, where orders are placed and money and stock shares change hands. Only live trading can tell the true profit and risk of the strategy. The change to the predictor will be reverted if it worsens the strategy\\u2019s profit or risk.\\n\\nQuants typically work on one of two types of trading systems: principal or agency. A principal strategy trades directly for the profit of the operator (the quant, or the company employing the quant). An agency strategy trades on behalf of customers as a service, helping customers reduce their trading costs.\\n\\nThere are many variations to these two types of strategies. They may trade stocks, futures contracts, options, or many other financial products. Each product type typically has multiple exchanges around the world on which to trade.\\n\\nAlso, a key defining component of a strategy is its timescale. A principal strategy owns a stock (or other instrument) for some amount of time before selling it. That amount of time may be on the order of minutes, hours, days, or weeks. Sometimes even as long as months or as short as seconds. Each timescale requires a different predictor and a different understanding of risk.\\n\\nThe MLE and quant workflows are similar because their systems are similar. They typically consist of a predictive model fit on data and some decision-making code that determines how the prediction is used. A software engineer\\u2019s workflow is somewhat different and is the next topic.\\n\\n1.1.3 Software engineer\\u2019s workflow\\n\\nSWEs work on a broad range of systems. In this text, we\\u2019ll define SWE problems as those that do not involve building models from data (thus differentiating them from MLEs and quants). SWEs build compilers, caching systems, web servers, trading system infrastructure (on which trading strategies run), and much more.\\n\\nAs an example, let\\u2019s consider the problem of improving the response time of a search engine with the goal of lowering the \\u201cbounce rate,\\u201d which is the probability that a user will navigate away from a website after seeing just one page. Figure 1.4 shows the SWE\\u2019s workflow.\\n\\nFigure 1.4 Example workflow for a software engineer building a search engine server. The server queries, aggregates, and transforms relevant data before sending the user a response. (1) The SWE changes the transformation portion of the code. (2) They time the code offline, verifying that it takes less time than the old code to transform several test data sets. (3) Running in production, the SWE measures whether the use of this new code results in a lower bounce rate, the business-relevant metric. If so, the new code is accepted as a permanent part of the system.\\n\\nThis SWE has built a search engine. It is a web server that responds to a user\\u2019s request by querying internal sources for a data set, transforming that data set, and delivering a formatted response to the user. Users are very sensitive to the time it takes for a web server to respond. If it takes too long, a user may navigate away from the web page before the response is delivered.\\n\\nWhile there are many ways to slow down a web server\\u2019s response (slow browser, slow network, cache misses, etc.), this SWE has a hypothesis that it\\u2019s the data transformation step that is too slow. To fix the problem, they subject their hypothesis to the workflow:\\n\\n1. Implement change\\u2014The SWE implements a code change that they expect to speed up the transformation step.\\n2. Evaluate offline\\u2014This code is run and timed offline on many samples of the internal data sets that resulted from previous user requests. If it proves to be faster, it passes to the next stage.\\n3. Measure online\\u2014The code change is deployed to production where responses are served to real users. The SWE measures the bounce rate and compares it to the bounce rate before the code change. If the new code lowers the bounce rate, it is accepted as a permanent part of the system.\\n\\nEngineering teams tend to generate many creative ideas for improving the system they work on. If these ideas are the raw material, the workflow is the factory that processes them\\u2014steadily and reliably\\u2014into system improvements.\\n\\nEach pass through the workflow ends with an online measurement of business metrics. That measurement is taken via an experiment on a live production system.\\n\\n1.2 Measuring by experiment\\n\\nThe engineered systems encountered in trading and technology are complex. This complexity can make it difficult to measure the impact of changes made to them. Consider a website that sells a product. A useful business metric might be daily revenue, the total number of dollars paid to the company by customers each day. That number depends on the quality of the product, its competition, how many people know about the product, how many people have already bought it, whether people are more inclined to shop on a given day (e.g., is it a weekend? Is it Black Friday?), how easy it is to navigate and understand the website, and so on. Many, many factors affect daily revenue, and many of them are not under the control of the company.\\n\\nIf you were to make a change to this website and record a day\\u2019s revenue, how could you say whether the change improved that revenue? Would you have made more or less on the day you measured if you hadn\\u2019t made the change? More importantly, would you expect to make more or less in the future if you left the change in or took it out? These questions can be answered by running experiments.\\n\\n1.2.1 Experimental methods\\n\\nExperimental methods ignore all the other factors that affect a business metric and tease out just the impact of the change you made to the system. Surprisingly, satisfyingly, experiments even account for the impact of the factors that are unknown to you, the engineer (chapter 2 discusses this in detail). It\\u2019s this ability to isolate the impact of your system change and ignore everything else that makes an experiment the right tool for the job of measuring business impact.\\n\\nExperiments are indeed valuable, but that value comes at a cost. Experiments take time to run, and they risk generating suboptimal system performance (e.g., if the change the engineer just implemented makes things worse instead of better) or damaging it (e.g., due to a bug in the new code). To get the most out of experimentation, we\\u2019ll try to minimize these costs. Chapter 2 presents the idea of experiment design, where we minimize the amount of time an experiment will take to run while still giving the results we need. The subsequent chapters on experimental methods, chapters 3 through 6, all discuss ways to reduce these costs further in specific situations. Chapters 3 and 5, which cover bandit algorithms, make the experiment design adaptive, so that while the experiment is running and collecting measurements, the design steadily improves.\\n\\nRecall that some system changes require the measurement of business metrics for multiple configurations to discover which is best. This induces a high measurement cost. The methods of chapters 4 and 6\\u2014response surface methodology and Bayesian optimization, respectively\\u2014use statistical inference to make good guesses about which system configurations are most promising, thus reducing the total number of measurements needed to find the best configuration.\\n\\nThese methods have been used in industry anywhere from 10 to 70 years (depending on the method) and are popular in the fields in which I work\\u2014quantitative trading and social media. What makes trading and technology so amenable to experimentation is that systems in these industries have many interactions with the world. Trading systems can send thousands or tens of thousands of orders per day. Websites may have from thousands to billions (for the largest websites) of requests per day. Each interaction provides an opportunity to experiment.\\n\\nDrawing on personal experience, discussions with colleagues, and interviews specifically for the preparation of this book, I have tried to limit the material to a set of methods proven to work well in practice. Along with explanations of methods and real-world examples, I\\u2019ve also collected practical problems and pitfalls.\\n\\n1.2.2 Practical problems and pitfalls\\n\\nAll these experimental methods assume you know your business metric. Chapter 7 discusses how to define one and how there\\u2019s usually more than one to consider. It also looks more closely at how to interpret experiment results and how that may be complicated when there are multiple metrics and multiple decision-makers involved.\\n\\nFinally, chapter 8 lists ways in which real-world data can deviate from the assumptions made in the development of the experimental methods and common sources of error in interpretation of results.\\n\\nOne practical problem worth addressing before even getting into the details of experimentation is the question of whether you should experiment at all. It takes time and effort to build the tools needed to design, measure, and analyze changes to your system. You should get something in return for all that work. The next section discusses some common arguments against experimentation and presents counterarguments.\\n\\n1.3 Why are experiments necessary?\\n\\nAny SWE is likely familiar with the admonition, attributed to Donald Knuth, that \\u201cpremature optimization is the root of all evil\\u201d\\u2014that is, rather than implement ideas that you expect will make your code run faster (or better in some other way) at the outset, first write simple code to solve the problem, devise a way to time the code, then test your ideas one at a time to see which ones actually speed things up. It\\u2019s too difficult to reason about everything that could affect speed\\u2014the whole code base, the computer architecture, the operating system, and so on\\u2014all at once, so you rely on a test.\\n\\nSimilar reasoning applies to improving business metrics. There are too many factors that could affect business metrics for a web product, including all the software engineering factors listed above, as well as data quality, model quality, changes in user sentiment, changes in browser technology, news of the day, and much more. This is the case for any engineered system: many factors affect business metrics, and they do so in complicated ways. Experimentation is necessary to accurately measure the impact on business metrics of a change to the system.\\n\\nThere are other tools available to assess the business-metric impact of a system change. Some examples are\\n\\n1. Domain knowledge\\n2. Offline model quality\\n3. Simulation\\n\\nThese tools are discussed in detail below. You\\u2019ll see that they have two things in common: (1) they are cheaper (less resource-intensive) to use, and (2) they are less accurate than an experimental result. These tools may be useful supplements to your decision-making, but they can\\u2019t replace experiments.\\n\\n1.3.1 Domain knowledge\\n\\nDomain knowledge is the specialized knowledge of a field, a market, or a business that people acquire through education and experience. You might think this kind of knowledge would make people good at predicting which new ideas will make a positive business impact. But for the past 10 years, I\\u2019ve given an informal survey to my quant coworkers. I\\u2019ve asked, \\u201cOf the ideas you\\u2019ve implemented and tested, how many have actually worked?\\u201d The answer every single time has been 1 in 10. And it\\u2019s always been said with a chuckle and an air of resignation. That survey isn\\u2019t exactly scientific, but similar stories come from elsewhere, too. Microsoft reports that only one-third of experiments improve metrics. Amazon reports a success rate below 50%. Netflix says only 10%. Even though the people generating the ideas had domain knowledge, most experiments failed to produce the expected results. There seem to be aspects of the world that keep most good ideas from working.\\n\\nOne aspect is complexity. Your system is likely made up of many components: hardware components like computers and network switches, software components (both in-house and third-party), and human elements\\u2014operators, suppliers, customers. These components interact with each other, with the physical environment, and with society at large. Computers interact via networks. Humans interact with each other online and in person. They also interact with your servers through a browser or an API.\\n\\nThe physical environment includes the temperature of a data center\\u2014which, when too high, adversely impacts computer performance or causes failure. It also includes the weather, which affects people\\u2019s behavior. When the weather\\u2019s bad, do people use your product more because they can\\u2019t engage in outdoor activities? Do their posts or comments reflect their mood, which is in turn affected by the weather? There is evidence that sunshine in the morning in New York City is correlated with increased stock returns on that day on the New York Stock Exchange. The proposed causal mechanism is that sunshine makes the traders more optimistic. No engineer\\u2014or anyone, for that matter\\u2014could be expected to anticipate effects like this just from experience or reasoning.\\n\\nTo put a finer point on it, if you have N components in your system, you have ~N^2 pair-wise interactions. In other words, if your system has many components, then it has a huge number of interactions. That\\u2019s too much for a person to consider when trying to guess the impact a system change will have on business metrics.\\n\\nGenerally, we\\u2019ll ignore most of that complexity when reasoning about a system in order to make things more manageable. We\\u2019ll create a mental model or even a mathematical model. In either case, the model of how your system operates contains the information about the system that you deemed important enough to include. In some models, this information might be called the signal. You leave out irrelevant details, which you might call noise. There\\u2019s a third category of things that affect your system\\u2019s performance: the things you didn\\u2019t even consider, because you don\\u2019t know about them. The \\u201cunknown unknowns,\\u201d they\\u2019re sometimes called. These things could affect experimental results by any amount, either positively or negatively. You won\\u2019t anticipate them or have intuition about them because they\\u2019re missing from your model.\\n\\nIt\\u2019s plausible that the \\u201cunknown unknowns\\u201d of your system might include its most valuable aspects. A Harvard Business Review article tells the story of a proposed change to Microsoft\\u2019s Bing search engine. A domain knowledge-based decision made the change a low priority for implementation, but when it was finally coded up and put into production, it had a tremendous positive impact on revenue (over $100 million per year). It was simply the case that no one could understand the system\\u2014the code, the design, the users, and so on\\u2014completely enough to predict the dramatic impact of that change. Not because they weren\\u2019t smart. Not because they weren\\u2019t knowledgeable. Just because Bing, the user base, and the world they interact with are collectively just too complex.\\n\\nIf your company is competitive and surviving, there\\u2019s a good chance your \\u201cunknown unknowns\\u201d overlap with your competitors\\u2019. If that\\u2019s the case, then to do something novel\\u2014to find value where your competitors haven\\u2019t\\u2014you\\u2019ll need to make changes to your system that you can\\u2019t evaluate with your existing domain knowledge. You\\u2019ll need to run experiments instead.\\n\\nDomain knowledge is valuable. It will help you generate ideas and prioritize them\\u2014to make good bets. But domain knowledge won\\u2019t tell you outcomes. To understand impact on business metrics, you need to take experimental measurements. In addition, I posit that the most valuable changes you make to your system may come as surprises, creating impact unpredicted by domain knowledge.\\n\\n1.3.2 Offline model quality\\n\\nIt is common practice among MLEs to include a prediction model (e.g., a classifier) as a component in a system. It is not an uncommon experience to improve a model\\u2019s fit-quality metric (e.g., cross-entropy) and yet not see the business metric improve when the model is deployed.\\n\\nLet\\u2019s say you build a model that predicts whether a user will click on news articles about sports. You gather a data set from production logs. It contains examples of sports articles that were presented to a user along with a record of which articles the user clicked on. Your model analyzes each article\\u2019s headline and predicts clicks very well. When you\\u2019re done building your model, you test it on out-of-sample data\\u2014data that wasn\\u2019t used in the fitting process\\u2014just to be sure you didn\\u2019t overfit. The model works great.\\n\\nNext you put your model into production like this: Every time a user loads the sports news page, you sort the articles by your model\\u2019s prediction, hoping to show the articles the user is more interested in nearer to the top of the list. You find that the user isn\\u2019t more likely to click on the articles near the top. In fact, your model no longer seems to predict clicks very well. The model wasn\\u2019t overfit. You checked for that. It\\u2019s something different. The data used to fit your model was missing counterfactuals\\u2014events that happen in your system after you deploy a change but that didn\\u2019t happen before deployment.\\n\\nThe historical data you used to fit the model was generated by the system without your model in it. The articles were sorted some other way (perhaps sorted by date, or maybe using a different click-prediction model). When you fit your model, you were teaching it how users responded to that old system, the one with the old sorting method. Users responded differently to the new sorting method. It is difficult, if not impossible, to predict exactly how users will respond to the deployment of a new model.\\n\\nThe same experience might be had by a quant. They could build a new price-change prediction model using a regression, find that it has a higher R^2 (a common measure of the quality of a fit) than their old model, and works well out-of-sample, but still, when deployed, the profit of the strategy does not improve. The market is made up of traders\\u2014some algorithmic, some human\\u2014and they will respond differently to the new model\\u2019s presence in the market than they did to the old model\\u2019s. In this case, during fitting, the quant taught the new model about the old market, the one in which the new model was not a participant.\\n\\nThis is such a common experience that most quants and MLEs will (eventually) be familiar with it. The Facebook ML Field Guide, episode 6 refers to this problem as the \\u201conline-offline gap.\\u201d The only way to be sure you\\u2019ve improved the system is to run the final stage of the workflow, the online measurement.\\n\\n1.3.3 Simulation\\n\\nSimulations are tools that estimate a system\\u2019s business metrics offline. They might combine logged data, models of users or markets, scientific models, or heuristics. They can vary considerably in their form from domain to domain.\\n\\nSimulations differ from the simple fitting metrics (cross-entropy or R^2) discussed in the previous section. Simulations typically account for all components of a system and aim to produce numbers like revenue or user engagement that may be compared to the numbers that come from experimental measurements.\\n\\nFor example, a standard quant\\u2019s tool is a trading simulation. Offline, it runs historical market data\\u2014trades and quotes\\u2014through the same trading strategy code that is used in production. When that strategy asks to execute a trade, the simulator mimics the behavior of the market using heuristics or a model of the market. From this simulation, a quant can estimate profit, risk, shares traded, and other useful business metrics.\\n\\nSimulations can give more precise answers\\u2014meaning numbers with smaller error bars\\u2014than experiments because they can use much more data. For example, a single simulation might process 1 month to 10 years of data, depending on the timescale over which the strategy trades, in a single run. This simulation might take minutes to hours to run, depending on the complexity of the strategy. An experiment, on the other hand, that takes a measurement with 1 month of data needs to run for 1 month. Want 10 years of experimental data? You\\u2019ll wait 10 years.\\n\\nSimulations may also be run multiple times on the same data set. Each run could try slight variations on the same strategy and allow the quant to choose the best one\\u2014the one with the best profit-to-risk tradeoff, for example\\u2014to trade in production. With experiments multiple runs are impossible. You can\\u2019t trade for a month, say, then \\u201crewind\\u201d real life and trade again with a different strategy. There are effective ways to compare different strategies experimentally, but the process is orders of magnitude faster in simulation.\\n\\nSimulations may be more precise and faster, but experiments are more accurate. Simulations might be biased (inaccurate) because of missing counterfactuals, just like prediction models. What happens, for example, when a trading strategy sends an order to an exchange? It might show up in the market, and other traders will see and respond to it. This changes future market data, which is then seen by the trading strategy and used for its decisions, and so on. Other traders\\u2019 real responses to our actions simply don\\u2019t exist in simulation.\\n\\nMLEs use simulation, too. Engineers working on Facebook Feed use a simulator that replays logged data through the Feed code that estimates users\\u2019 responses. In \\u201cCombining online and offline tests to improve News Feed ranking,\\u201d they note that their offline simulations are biased. While the simulation results are related to real results, they don\\u2019t match exactly and the relationship between them is nontrivial. (The blog post goes on to design a model-based mapping from simulation results to experimental results.)\\n\\nResearchers who study a field called evolutionary robotics design robot controllers\\u2014pieces of code that take in sensor information and output commands to a robot\\u2019s actuators\\u2014using algorithms inspired by evolution. The evolutionary algorithms search for controller parameters that optimize the performance of the robot as measured by a simulation. The researchers notice so often that controllers designed in simulation don\\u2019t work on real robots that they have coined a term for this effect: the reality gap.\\n\\nIn a live-streamed event, Tesla Autonomy Day, CEO Elon Musk is asked why Tesla relies so much on data collected from real drivers instead of training their autonomous driving controller via simulation. He says that they do use simulation, but that since they \\u201cdon\\u2019t know what they don\\u2019t know\\u201d\\u2014and all of what they don\\u2019t know would be missing from the simulation\\u2014they invest effort and money into collecting lots of real data. In the same video, AI director Andrej Karpathy gives several examples of rare, unanticipated images from around the world that need to be interpreted by their vision system. Without appealing to real-world data, their system would never learn to deal with these images.\\n\\nSimulation is a powerful offline design tool. Simulations can be used in the second stage of the workflow to generate estimates of business metrics. Because they tend to be biased, and you can never know exactly how, it is always necessary to test changes to your system with an experiment.\\n\\n1 Summary\\n\\n1. Experimental optimization is the process of improving an engineered system using measurement-based design decisions.\\n2. Experimental methods minimize the time and risk associated with experimental measurements.\\n3. Experiments are the most accurate way to measure the impact on business metrics of changes to an engineered system.\\n4. Domain knowledge, prediction models, and simulation are powerful supplements to experiments but are not replacements for them.\", \"refusal\": null, \"role\": \"assistant\", \"annotations\": [], \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1756932450, \"model\": \"gpt-5-mini-2025-08-07\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 6877, \"prompt_tokens\": 12900, \"total_tokens\": 19777, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Cost: $0.016978999999999998\n",
      "Input tokens: 12900\n",
      "Output tokens: 6877\n",
      "Speaker 1: 1 Optimizing systems by experiment\n",
      "\n",
      "Speaker 1: This chapter covers\n",
      "\n",
      "Speaker 1: 1. Optimizing an engineered system\n",
      "Speaker 1: 2. Exploring what experiments are\n",
      "Speaker 1: 3. Learning why experiments are uniquely valuable\n",
      "\n",
      "Speaker 1: The past 20 years have seen a surge in interest in the development of experimental methods used to measure and improve engineered systems, such as web products, automated trading systems, and software infrastructure. Experimental methods have become more automated and more efficient. They have scaled up to large systems like search engines or social media sites. These methods generate continuous, automated performance improvement of live production systems.\n",
      "\n",
      "Speaker 1: Using these experimental methods, engineers measure the business impact of the changes they make to their systems and determine the optimal settings under which to run them. We call this process experimental optimization.\n",
      "\n",
      "Speaker 1: This book teaches several experimental optimization methods used by engineers working in trading and technology. We’ll discuss systems built by three specific types of engineers:\n",
      "\n",
      "Speaker 1: 1. Machine learning engineers\n",
      "Speaker 1: 2. Quantitative traders (“quants”)\n",
      "Speaker 1: 3. Software engineers\n",
      "\n",
      "Speaker 1: Machine learning engineers often work on web products like search engines, recommender systems, and ad placement systems. Quants build automated trading systems. Software engineers build infrastructure and tooling such as web servers, compilers, and event processing systems.\n",
      "\n",
      "Speaker 1: These engineers follow a common process, or workflow, that is an endless loop of steady system improvement. Figure 1.1 shows this common workflow.\n",
      "\n",
      "Speaker 1: Figure 1.1 Common engineering workflow. (1) A new idea is first implemented as a code change to the system. (2) Typically, some offline evaluation is performed that rejects ideas that are expected to negatively impact business metrics. (3) The change is pushed into the production system, and business metrics are measured there, online. Accepted changes become permanent parts of the system. The whole workflow repeats, creating reliable, continuous improvement of the system.\n",
      "\n",
      "Speaker 1: The common workflow creates progressive improvement of an engineered system. An individual or a team generates ideas that they expect will improve the system, and they pass each idea through the workflow. Good ideas are accepted into the system, and bad ideas are rejected:\n",
      "\n",
      "Speaker 1: 1. Implement change—First, an engineer implements an idea as a code change, an update to the system’s software. In this stage, the code is subjected to typical software engineering quality controls, like code review and unit testing. If it passes all tests, it moves on to the next stage.\n",
      "Speaker 1: 2. Evaluate offline—The business impact of the code change is evaluated offline, away from the production system. This evaluation typically uses data previously logged by the production system to produce rough estimates of business metrics such as revenue or the expected number of clicks on an advertisement. If these estimates show that applying this code change to the production system would worsen business metrics, then the code change is rejected. Otherwise, it is passed to the final stage.\n",
      "Speaker 1: 3. Measure online—The change is pushed into production, where its impact on business metrics is measured. The code change might require some configuration—the setting of numerical parameters or Boolean flags. If so, the engineer will measure business metrics for multiple configurations to determine which is best. If no improvements to business metrics can be made by applying (and configuring) this code change, then the code change is rejected. Otherwise, the change is made permanent and the system improves.\n",
      "\n",
      "Speaker 1: This book deals with the final stage, “measure online.” In this stage, you run an experiment on the live production system. Experimentation is valuable because it produces a measurement from the real system, which is information you couldn’t get any other way. But experimentation on a live system takes time. Some experiments take days or weeks to run. And it is not without risk. When you run an experiment, you may lose money, alienate users, or generate bad press or social media chatter as users notice and complain about the changes you’re making to your system. Therefore, you need to take measurements as quickly and precisely as possible to minimize the ill effects of ideas—call them costs for brevity—that don’t work and to take maximal advantage of ones that do.\n",
      "\n",
      "Speaker 1: To extract the most value from a new bit of code, you need to configure it optimally. You could liken the process of finding the best configuration to tuning an old AM or FM radio or tuning a guitar string. You typically turn a knob up and down and listen to see whether you’re getting good results. Set the knob too high or too low and your radio will be noisy, or your guitar will be sharp or flat. So it is with code configuration parameters (often referred to as knobs in code your author has read). You want them set to just the right values to give maximal business impact—whether that’s revenue or clicks or some other metric. Note that the need to run costly experiments is what specifies experimental optimization methods as a subset of optimization methods more generally.\n",
      "\n",
      "Speaker 1: In this chapter, we’ll discuss engineering workflows for each of the engineer types listed earlier—machine learning engineer (MLE), quant, and software engineer (SWE). We’ll see what kinds of systems they work on, the business metrics they measure, and how each stage of the generic workflow is implemented.\n",
      "\n",
      "Speaker 1: In your organization, you might hear of alternative ways of evaluating changes to a system. Common suggestions are domain knowledge, model-based estimates, and simulation. We’ll discuss the reason why these tools, while valuable, can’t substitute for an experimental measurement.\n",
      "\n",
      "Speaker 1: 1.1 Examples of engineering workflows\n",
      "\n",
      "Speaker 1: While the engineers listed earlier may work in different domains, their overall workflows are similar. Their workflows can be seen as specific cases of the common engineering workflow we described in figure 1.1: implement change, evaluate offline, measure online. Let’s look in detail at an example workflow for an MLE, for a quant, and for an SWE.\n",
      "\n",
      "Speaker 1: 1.1.1 Machine learning engineer’s workflow\n",
      "\n",
      "Speaker 1: Imagine an MLE who works on a web-based news site. Their workflow might look like figure 1.2.\n",
      "\n",
      "Speaker 1: Figure 1.2 Example workflow for a machine learning engineer building a news-based website. The site contains an ML component that predicts clicks on news articles. (1) The MLE fits a new predictor. (2) An estimate of ad revenue from the new predictor is made using logs of user clicks and ad rates. (3) The new predictor is deployed to production and actual ad revenue is measured. If it improves ad revenue, then it is accepted into the system.\n",
      "\n",
      "Speaker 1: The key machine learning component of the website is a predictor model that predicts which news articles a user will click on. The predictor might take as input many features, such as information about the user’s demographics, the user’s previous activity on the website, and information about the news article’s title or its content. The predictor’s output will be an estimate of the probability that a specific user will click on a given news article. The website could use those predictions to rank and sort news articles on a headlines-summary page hoping to put more appealing news higher up on the page.\n",
      "\n",
      "Speaker 1: Figure 1.2 depicts the workflow for this system. When the MLE comes up with an idea to improve the predictor—a new feature or a new model type—the idea is subjected to the workflow:\n",
      "\n",
      "Speaker 1: 1. Implement change—The MLE fits the new predictor to logged data. If it produces better predictions on the logged data than the previous predictor, it passes to the next stage.\n",
      "Speaker 1: 2. Evaluate offline—The business goal is to increase revenue from ads that run on the website, not simply to improve click predictions. Translating improved predictions into improved revenue is not straightforward, but methods exist that give useful estimates for some systems. If the estimates do not look very bad, the predictor will pass on to the next stage.\n",
      "Speaker 1: 3. Measure online—The MLE deploys the predictor to production, and real users see their headlines ranked with it. The MLE measures the ad revenue and compares it to the ad revenue produced by the old predictor. If the new predictor improves ad revenue, then it is accepted into the system.\n",
      "\n",
      "Speaker 1: A news-based website may have many other components besides a click predictor. Each of those components would be exposed to the same workflow as the predictor, ensuring that the system steadily produces more ad revenue.\n",
      "\n",
      "Speaker 1: MLEs work on many kinds of systems. Sorting news headlines by click probability is an example of a broader class of system called a recommender system. Recommender systems are used to rank videos, music, social media posts, consumer goods, and more. Search engines are a similar ML system, in that they may rank search results specifically for the user. Targeted advertising, which chooses ads specifically for the user, is another type of MLE system. Now let’s turn to finance and see how quants follow the same workflow pattern.\n",
      "\n",
      "Speaker 1: 1.1.2 Quantitative trader’s workflow\n",
      "\n",
      "Speaker 1: A quant’s workflow is very similar to the MLE’s workflow. Only the details change. There’s a different prediction to be made, for example. See figure 1.3.\n",
      "\n",
      "Speaker 1: Figure 1.3 Example workflow for a quant designing an automated trading strategy. The strategy contains a price-change predictor. (1) The quant produces a new predictor. (2) Profit and risk estimates come from a simulation using historical market data. (3) Live trading measures the true profit and risk. If the new predictor increases profit and/or reduces risk, then it is accepted into the system.\n",
      "\n",
      "Speaker 1: This quant is building an automated trading strategy. It is a piece of software that issues BUY and SELL orders to an exchange hoping to, as they say, buy low and sell high. A key component is a model that predicts change in the price of the financial instrument (e.g., a stock) being traded. If the price is predicted to increase, it’s a good time to issue a BUY order. Similarly, if the price is predicted to decrease, it’s a good time to SELL. The business metric for this system is profit. But it’s also risk. Quants want both higher profit and lower risk. It is not uncommon (in practice, it’s the norm) to be concerned with more than one business metric when optimizing a system. Chapter 7, section 3 will discuss this important practical point in detail.\n",
      "\n",
      "Speaker 1: Figure 1.3 shows the quant’s workflow. Changes to the trading strategy pass through these stages:\n",
      "\n",
      "Speaker 1: 1. Implement change—The quant fits the new price-change predictor to historical market data and verifies that it produces better predictions than the previous predictor.\n",
      "Speaker 1: 2. Evaluate offline—Better price predictions do not guarantee higher profits (or lower risk). The full trading strategy—predictor, BUY/SELL orders, and so on—is run through a simulation (also called a backtest) on historical market data. The simulation generates predictions and mimics buying and selling to estimate profit and risk. Sufficient improvement in the strategy will allow the predictor to pass to the next stage.\n",
      "Speaker 1: 3. Measure online—The predictor is deployed to live trading, where orders are placed and money and stock shares change hands. Only live trading can tell the true profit and risk of the strategy. The change to the predictor will be reverted if it worsens the strategy’s profit or risk.\n",
      "\n",
      "Speaker 1: Quants typically work on one of two types of trading systems: principal or agency. A principal strategy trades directly for the profit of the operator (the quant, or the company employing the quant). An agency strategy trades on behalf of customers as a service, helping customers reduce their trading costs.\n",
      "\n",
      "Speaker 1: There are many variations to these two types of strategies. They may trade stocks, futures contracts, options, or many other financial products. Each product type typically has multiple exchanges around the world on which to trade.\n",
      "\n",
      "Speaker 1: Also, a key defining component of a strategy is its timescale. A principal strategy owns a stock (or other instrument) for some amount of time before selling it. That amount of time may be on the order of minutes, hours, days, or weeks. Sometimes even as long as months or as short as seconds. Each timescale requires a different predictor and a different understanding of risk.\n",
      "\n",
      "Speaker 1: The MLE and quant workflows are similar because their systems are similar. They typically consist of a predictive model fit on data and some decision-making code that determines how the prediction is used. A software engineer’s workflow is somewhat different and is the next topic.\n",
      "\n",
      "Speaker 1: 1.1.3 Software engineer’s workflow\n",
      "\n",
      "Speaker 1: SWEs work on a broad range of systems. In this text, we’ll define SWE problems as those that do not involve building models from data (thus differentiating them from MLEs and quants). SWEs build compilers, caching systems, web servers, trading system infrastructure (on which trading strategies run), and much more.\n",
      "\n",
      "Speaker 1: As an example, let’s consider the problem of improving the response time of a search engine with the goal of lowering the “bounce rate,” which is the probability that a user will navigate away from a website after seeing just one page. Figure 1.4 shows the SWE’s workflow.\n",
      "\n",
      "Speaker 1: Figure 1.4 Example workflow for a software engineer building a search engine server. The server queries, aggregates, and transforms relevant data before sending the user a response. (1) The SWE changes the transformation portion of the code. (2) They time the code offline, verifying that it takes less time than the old code to transform several test data sets. (3) Running in production, the SWE measures whether the use of this new code results in a lower bounce rate, the business-relevant metric. If so, the new code is accepted as a permanent part of the system.\n",
      "\n",
      "Speaker 1: This SWE has built a search engine. It is a web server that responds to a user’s request by querying internal sources for a data set, transforming that data set, and delivering a formatted response to the user. Users are very sensitive to the time it takes for a web server to respond. If it takes too long, a user may navigate away from the web page before the response is delivered.\n",
      "\n",
      "Speaker 1: While there are many ways to slow down a web server’s response (slow browser, slow network, cache misses, etc.), this SWE has a hypothesis that it’s the data transformation step that is too slow. To fix the problem, they subject their hypothesis to the workflow:\n",
      "\n",
      "Speaker 1: 1. Implement change—The SWE implements a code change that they expect to speed up the transformation step.\n",
      "Speaker 1: 2. Evaluate offline—This code is run and timed offline on many samples of the internal data sets that resulted from previous user requests. If it proves to be faster, it passes to the next stage.\n",
      "Speaker 1: 3. Measure online—The code change is deployed to production where responses are served to real users. The SWE measures the bounce rate and compares it to the bounce rate before the code change. If the new code lowers the bounce rate, it is accepted as a permanent part of the system.\n",
      "\n",
      "Speaker 1: Engineering teams tend to generate many creative ideas for improving the system they work on. If these ideas are the raw material, the workflow is the factory that processes them—steadily and reliably—into system improvements.\n",
      "\n",
      "Speaker 1: Each pass through the workflow ends with an online measurement of business metrics. That measurement is taken via an experiment on a live production system.\n",
      "\n",
      "Speaker 1: 1.2 Measuring by experiment\n",
      "\n",
      "Speaker 1: The engineered systems encountered in trading and technology are complex. This complexity can make it difficult to measure the impact of changes made to them. Consider a website that sells a product. A useful business metric might be daily revenue, the total number of dollars paid to the company by customers each day. That number depends on the quality of the product, its competition, how many people know about the product, how many people have already bought it, whether people are more inclined to shop on a given day (e.g., is it a weekend? Is it Black Friday?), how easy it is to navigate and understand the website, and so on. Many, many factors affect daily revenue, and many of them are not under the control of the company.\n",
      "\n",
      "Speaker 1: If you were to make a change to this website and record a day’s revenue, how could you say whether the change improved that revenue? Would you have made more or less on the day you measured if you hadn’t made the change? More importantly, would you expect to make more or less in the future if you left the change in or took it out? These questions can be answered by running experiments.\n",
      "\n",
      "Speaker 1: 1.2.1 Experimental methods\n",
      "\n",
      "Speaker 1: Experimental methods ignore all the other factors that affect a business metric and tease out just the impact of the change you made to the system. Surprisingly, satisfyingly, experiments even account for the impact of the factors that are unknown to you, the engineer (chapter 2 discusses this in detail). It’s this ability to isolate the impact of your system change and ignore everything else that makes an experiment the right tool for the job of measuring business impact.\n",
      "\n",
      "Speaker 1: Experiments are indeed valuable, but that value comes at a cost. Experiments take time to run, and they risk generating suboptimal system performance (e.g., if the change the engineer just implemented makes things worse instead of better) or damaging it (e.g., due to a bug in the new code). To get the most out of experimentation, we’ll try to minimize these costs. Chapter 2 presents the idea of experiment design, where we minimize the amount of time an experiment will take to run while still giving the results we need. The subsequent chapters on experimental methods, chapters 3 through 6, all discuss ways to reduce these costs further in specific situations. Chapters 3 and 5, which cover bandit algorithms, make the experiment design adaptive, so that while the experiment is running and collecting measurements, the design steadily improves.\n",
      "\n",
      "Speaker 1: Recall that some system changes require the measurement of business metrics for multiple configurations to discover which is best. This induces a high measurement cost. The methods of chapters 4 and 6—response surface methodology and Bayesian optimization, respectively—use statistical inference to make good guesses about which system configurations are most promising, thus reducing the total number of measurements needed to find the best configuration.\n",
      "\n",
      "Speaker 1: These methods have been used in industry anywhere from 10 to 70 years (depending on the method) and are popular in the fields in which I work—quantitative trading and social media. What makes trading and technology so amenable to experimentation is that systems in these industries have many interactions with the world. Trading systems can send thousands or tens of thousands of orders per day. Websites may have from thousands to billions (for the largest websites) of requests per day. Each interaction provides an opportunity to experiment.\n",
      "\n",
      "Speaker 1: Drawing on personal experience, discussions with colleagues, and interviews specifically for the preparation of this book, I have tried to limit the material to a set of methods proven to work well in practice. Along with explanations of methods and real-world examples, I’ve also collected practical problems and pitfalls.\n",
      "\n",
      "Speaker 1: 1.2.2 Practical problems and pitfalls\n",
      "\n",
      "Speaker 1: All these experimental methods assume you know your business metric. Chapter 7 discusses how to define one and how there’s usually more than one to consider. It also looks more closely at how to interpret experiment results and how that may be complicated when there are multiple metrics and multiple decision-makers involved.\n",
      "\n",
      "Speaker 1: Finally, chapter 8 lists ways in which real-world data can deviate from the assumptions made in the development of the experimental methods and common sources of error in interpretation of results.\n",
      "\n",
      "Speaker 1: One practical problem worth addressing before even getting into the details of experimentation is the question of whether you should experiment at all. It takes time and effort to build the tools needed to design, measure, and analyze changes to your system. You should get something in return for all that work. The next section discusses some common arguments against experimentation and presents counterarguments.\n",
      "\n",
      "Speaker 1: 1.3 Why are experiments necessary?\n",
      "\n",
      "Speaker 1: Any SWE is likely familiar with the admonition, attributed to Donald Knuth, that “premature optimization is the root of all evil”—that is, rather than implement ideas that you expect will make your code run faster (or better in some other way) at the outset, first write simple code to solve the problem, devise a way to time the code, then test your ideas one at a time to see which ones actually speed things up. It’s too difficult to reason about everything that could affect speed—the whole code base, the computer architecture, the operating system, and so on—all at once, so you rely on a test.\n",
      "\n",
      "Speaker 1: Similar reasoning applies to improving business metrics. There are too many factors that could affect business metrics for a web product, including all the software engineering factors listed above, as well as data quality, model quality, changes in user sentiment, changes in browser technology, news of the day, and much more. This is the case for any engineered system: many factors affect business metrics, and they do so in complicated ways. Experimentation is necessary to accurately measure the impact on business metrics of a change to the system.\n",
      "\n",
      "Speaker 1: There are other tools available to assess the business-metric impact of a system change. Some examples are\n",
      "\n",
      "Speaker 1: 1. Domain knowledge\n",
      "Speaker 1: 2. Offline model quality\n",
      "Speaker 1: 3. Simulation\n",
      "\n",
      "Speaker 1: These tools are discussed in detail below. You’ll see that they have two things in common: (1) they are cheaper (less resource-intensive) to use, and (2) they are less accurate than an experimental result. These tools may be useful supplements to your decision-making, but they can’t replace experiments.\n",
      "\n",
      "Speaker 1: 1.3.1 Domain knowledge\n",
      "\n",
      "Speaker 1: Domain knowledge is the specialized knowledge of a field, a market, or a business that people acquire through education and experience. You might think this kind of knowledge would make people good at predicting which new ideas will make a positive business impact. But for the past 10 years, I’ve given an informal survey to my quant coworkers. I’ve asked, “Of the ideas you’ve implemented and tested, how many have actually worked?” The answer every single time has been 1 in 10. And it’s always been said with a chuckle and an air of resignation. That survey isn’t exactly scientific, but similar stories come from elsewhere, too. Microsoft reports that only one-third of experiments improve metrics. Amazon reports a success rate below 50%. Netflix says only 10%. Even though the people generating the ideas had domain knowledge, most experiments failed to produce the expected results. There seem to be aspects of the world that keep most good ideas from working.\n",
      "\n",
      "Speaker 1: One aspect is complexity. Your system is likely made up of many components: hardware components like computers and network switches, software components (both in-house and third-party), and human elements—operators, suppliers, customers. These components interact with each other, with the physical environment, and with society at large. Computers interact via networks. Humans interact with each other online and in person. They also interact with your servers through a browser or an API.\n",
      "\n",
      "Speaker 1: The physical environment includes the temperature of a data center—which, when too high, adversely impacts computer performance or causes failure. It also includes the weather, which affects people’s behavior. When the weather’s bad, do people use your product more because they can’t engage in outdoor activities? Do their posts or comments reflect their mood, which is in turn affected by the weather? There is evidence that sunshine in the morning in New York City is correlated with increased stock returns on that day on the New York Stock Exchange. The proposed causal mechanism is that sunshine makes the traders more optimistic. No engineer—or anyone, for that matter—could be expected to anticipate effects like this just from experience or reasoning.\n",
      "\n",
      "Speaker 1: To put a finer point on it, if you have N components in your system, you have ~N^2 pair-wise interactions. In other words, if your system has many components, then it has a huge number of interactions. That’s too much for a person to consider when trying to guess the impact a system change will have on business metrics.\n",
      "\n",
      "Speaker 1: Generally, we’ll ignore most of that complexity when reasoning about a system in order to make things more manageable. We’ll create a mental model or even a mathematical model. In either case, the model of how your system operates contains the information about the system that you deemed important enough to include. In some models, this information might be called the signal. You leave out irrelevant details, which you might call noise. There’s a third category of things that affect your system’s performance: the things you didn’t even consider, because you don’t know about them. The “unknown unknowns,” they’re sometimes called. These things could affect experimental results by any amount, either positively or negatively. You won’t anticipate them or have intuition about them because they’re missing from your model.\n",
      "\n",
      "Speaker 1: It’s plausible that the “unknown unknowns” of your system might include its most valuable aspects. A Harvard Business Review article tells the story of a proposed change to Microsoft’s Bing search engine. A domain knowledge-based decision made the change a low priority for implementation, but when it was finally coded up and put into production, it had a tremendous positive impact on revenue (over $100 million per year). It was simply the case that no one could understand the system—the code, the design, the users, and so on—completely enough to predict the dramatic impact of that change. Not because they weren’t smart. Not because they weren’t knowledgeable. Just because Bing, the user base, and the world they interact with are collectively just too complex.\n",
      "\n",
      "Speaker 1: If your company is competitive and surviving, there’s a good chance your “unknown unknowns” overlap with your competitors’. If that’s the case, then to do something novel—to find value where your competitors haven’t—you’ll need to make changes to your system that you can’t evaluate with your existing domain knowledge. You’ll need to run experiments instead.\n",
      "\n",
      "Speaker 1: Domain knowledge is valuable. It will help you generate ideas and prioritize them—to make good bets. But domain knowledge won’t tell you outcomes. To understand impact on business metrics, you need to take experimental measurements. In addition, I posit that the most valuable changes you make to your system may come as surprises, creating impact unpredicted by domain knowledge.\n",
      "\n",
      "Speaker 1: 1.3.2 Offline model quality\n",
      "\n",
      "Speaker 1: It is common practice among MLEs to include a prediction model (e.g., a classifier) as a component in a system. It is not an uncommon experience to improve a model’s fit-quality metric (e.g., cross-entropy) and yet not see the business metric improve when the model is deployed.\n",
      "\n",
      "Speaker 1: Let’s say you build a model that predicts whether a user will click on news articles about sports. You gather a data set from production logs. It contains examples of sports articles that were presented to a user along with a record of which articles the user clicked on. Your model analyzes each article’s headline and predicts clicks very well. When you’re done building your model, you test it on out-of-sample data—data that wasn’t used in the fitting process—just to be sure you didn’t overfit. The model works great.\n",
      "\n",
      "Speaker 1: Next you put your model into production like this: Every time a user loads the sports news page, you sort the articles by your model’s prediction, hoping to show the articles the user is more interested in nearer to the top of the list. You find that the user isn’t more likely to click on the articles near the top. In fact, your model no longer seems to predict clicks very well. The model wasn’t overfit. You checked for that. It’s something different. The data used to fit your model was missing counterfactuals—events that happen in your system after you deploy a change but that didn’t happen before deployment.\n",
      "\n",
      "Speaker 1: The historical data you used to fit the model was generated by the system without your model in it. The articles were sorted some other way (perhaps sorted by date, or maybe using a different click-prediction model). When you fit your model, you were teaching it how users responded to that old system, the one with the old sorting method. Users responded differently to the new sorting method. It is difficult, if not impossible, to predict exactly how users will respond to the deployment of a new model.\n",
      "\n",
      "Speaker 1: The same experience might be had by a quant. They could build a new price-change prediction model using a regression, find that it has a higher R^2 (a common measure of the quality of a fit) than their old model, and works well out-of-sample, but still, when deployed, the profit of the strategy does not improve. The market is made up of traders—some algorithmic, some human—and they will respond differently to the new model’s presence in the market than they did to the old model’s. In this case, during fitting, the quant taught the new model about the old market, the one in which the new model was not a participant.\n",
      "\n",
      "Speaker 1: This is such a common experience that most quants and MLEs will (eventually) be familiar with it. The Facebook ML Field Guide, episode 6 refers to this problem as the “online-offline gap.” The only way to be sure you’ve improved the system is to run the final stage of the workflow, the online measurement.\n",
      "\n",
      "Speaker 1: 1.3.3 Simulation\n",
      "\n",
      "Speaker 1: Simulations are tools that estimate a system’s business metrics offline. They might combine logged data, models of users or markets, scientific models, or heuristics. They can vary considerably in their form from domain to domain.\n",
      "\n",
      "Speaker 1: Simulations differ from the simple fitting metrics (cross-entropy or R^2) discussed in the previous section. Simulations typically account for all components of a system and aim to produce numbers like revenue or user engagement that may be compared to the numbers that come from experimental measurements.\n",
      "\n",
      "Speaker 1: For example, a standard quant’s tool is a trading simulation. Offline, it runs historical market data—trades and quotes—through the same trading strategy code that is used in production. When that strategy asks to execute a trade, the simulator mimics the behavior of the market using heuristics or a model of the market. From this simulation, a quant can estimate profit, risk, shares traded, and other useful business metrics.\n",
      "\n",
      "Speaker 1: Simulations can give more precise answers—meaning numbers with smaller error bars—than experiments because they can use much more data. For example, a single simulation might process 1 month to 10 years of data, depending on the timescale over which the strategy trades, in a single run. This simulation might take minutes to hours to run, depending on the complexity of the strategy. An experiment, on the other hand, that takes a measurement with 1 month of data needs to run for 1 month. Want 10 years of experimental data? You’ll wait 10 years.\n",
      "\n",
      "Speaker 1: Simulations may also be run multiple times on the same data set. Each run could try slight variations on the same strategy and allow the quant to choose the best one—the one with the best profit-to-risk tradeoff, for example—to trade in production. With experiments multiple runs are impossible. You can’t trade for a month, say, then “rewind” real life and trade again with a different strategy. There are effective ways to compare different strategies experimentally, but the process is orders of magnitude faster in simulation.\n",
      "\n",
      "Speaker 1: Simulations may be more precise and faster, but experiments are more accurate. Simulations might be biased (inaccurate) because of missing counterfactuals, just like prediction models. What happens, for example, when a trading strategy sends an order to an exchange? It might show up in the market, and other traders will see and respond to it. This changes future market data, which is then seen by the trading strategy and used for its decisions, and so on. Other traders’ real responses to our actions simply don’t exist in simulation.\n",
      "\n",
      "Speaker 1: MLEs use simulation, too. Engineers working on Facebook Feed use a simulator that replays logged data through the Feed code that estimates users’ responses. In “Combining online and offline tests to improve News Feed ranking,” they note that their offline simulations are biased. While the simulation results are related to real results, they don’t match exactly and the relationship between them is nontrivial. (The blog post goes on to design a model-based mapping from simulation results to experimental results.)\n",
      "\n",
      "Speaker 1: Researchers who study a field called evolutionary robotics design robot controllers—pieces of code that take in sensor information and output commands to a robot’s actuators—using algorithms inspired by evolution. The evolutionary algorithms search for controller parameters that optimize the performance of the robot as measured by a simulation. The researchers notice so often that controllers designed in simulation don’t work on real robots that they have coined a term for this effect: the reality gap.\n",
      "\n",
      "Speaker 1: In a live-streamed event, Tesla Autonomy Day, CEO Elon Musk is asked why Tesla relies so much on data collected from real drivers instead of training their autonomous driving controller via simulation. He says that they do use simulation, but that since they “don’t know what they don’t know”—and all of what they don’t know would be missing from the simulation—they invest effort and money into collecting lots of real data. In the same video, AI director Andrej Karpathy gives several examples of rare, unanticipated images from around the world that need to be interpreted by their vision system. Without appealing to real-world data, their system would never learn to deal with these images.\n",
      "\n",
      "Speaker 1: Simulation is a powerful offline design tool. Simulations can be used in the second stage of the workflow to generate estimates of business metrics. Because they tend to be biased, and you can never know exactly how, it is always necessary to test changes to your system with an experiment.\n",
      "\n",
      "Speaker 1: 1 Summary\n",
      "\n",
      "Speaker 1: 1. Experimental optimization is the process of improving an engineered system using measurement-based design decisions.\n",
      "Speaker 1: 2. Experimental methods minimize the time and risk associated with experimental measurements.\n",
      "Speaker 1: 3. Experiments are the most accurate way to measure the impact on business metrics of changes to an engineered system.\n",
      "Speaker 1: 4. Domain knowledge, prediction models, and simulation are powerful supplements to experiments but are not replacements for them.\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-CBog6D8nCXaVCPHltOGpztdeqN4p0\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"1 Optimizing systems by experiment\\n\\nThis chapter covers\\n\\n1. Optimizing an engineered system\\n2. Exploring what experiments are\\n3. Learning why experiments are uniquely valuable\\n\\nThe past 20 years have seen a surge in interest in the development of experimental methods used to measure and improve engineered systems, such as web products, automated trading systems, and software infrastructure. Experimental methods have become more automated and more efficient. They have scaled up to large systems like search engines or social media sites. These methods generate continuous, automated performance improvement of live production systems.\\n\\nUsing these experimental methods, engineers measure the business impact of the changes they make to their systems and determine the optimal settings under which to run them. We call this process experimental optimization.\\n\\nThis book teaches several experimental optimization methods used by engineers working in trading and technology. We\\u2019ll discuss systems built by three specific types of engineers:\\n\\n1. Machine learning engineers\\n2. Quantitative traders (\\u201cquants\\u201d)\\n3. Software engineers\\n\\nMachine learning engineers often work on web products like search engines, recommender systems, and ad placement systems. Quants build automated trading systems. Software engineers build infrastructure and tooling such as web servers, compilers, and event processing systems.\\n\\nThese engineers follow a common process, or workflow, that is an endless loop of steady system improvement. Figure 1.1 shows this common workflow.\\n\\nFigure 1.1 Common engineering workflow. (1) A new idea is first implemented as a code change to the system. (2) Typically, some offline evaluation is performed that rejects ideas that are expected to negatively impact business metrics. (3) The change is pushed into the production system, and business metrics are measured there, online. Accepted changes become permanent parts of the system. The whole workflow repeats, creating reliable, continuous improvement of the system.\\n\\nThe common workflow creates progressive improvement of an engineered system. An individual or a team generates ideas that they expect will improve the system, and they pass each idea through the workflow. Good ideas are accepted into the system, and bad ideas are rejected:\\n\\n1. Implement change\\u2014First, an engineer implements an idea as a code change, an update to the system\\u2019s software. In this stage, the code is subjected to typical software engineering quality controls, like code review and unit testing. If it passes all tests, it moves on to the next stage.\\n2. Evaluate offline\\u2014The business impact of the code change is evaluated offline, away from the production system. This evaluation typically uses data previously logged by the production system to produce rough estimates of business metrics such as revenue or the expected number of clicks on an advertisement. If these estimates show that applying this code change to the production system would worsen business metrics, then the code change is rejected. Otherwise, it is passed to the final stage.\\n3. Measure online\\u2014The change is pushed into production, where its impact on business metrics is measured. The code change might require some configuration\\u2014the setting of numerical parameters or Boolean flags. If so, the engineer will measure business metrics for multiple configurations to determine which is best. If no improvements to business metrics can be made by applying (and configuring) this code change, then the code change is rejected. Otherwise, the change is made permanent and the system improves.\\n\\nThis book deals with the final stage, \\u201cmeasure online.\\u201d In this stage, you run an experiment on the live production system. Experimentation is valuable because it produces a measurement from the real system, which is information you couldn\\u2019t get any other way. But experimentation on a live system takes time. Some experiments take days or weeks to run. And it is not without risk. When you run an experiment, you may lose money, alienate users, or generate bad press or social media chatter as users notice and complain about the changes you\\u2019re making to your system. Therefore, you need to take measurements as quickly and precisely as possible to minimize the ill effects of ideas\\u2014call them costs for brevity\\u2014that don\\u2019t work and to take maximal advantage of ones that do.\\n\\nTo extract the most value from a new bit of code, you need to configure it optimally. You could liken the process of finding the best configuration to tuning an old AM or FM radio or tuning a guitar string. You typically turn a knob up and down and listen to see whether you\\u2019re getting good results. Set the knob too high or too low and your radio will be noisy, or your guitar will be sharp or flat. So it is with code configuration parameters (often referred to as knobs in code your author has read). You want them set to just the right values to give maximal business impact\\u2014whether that\\u2019s revenue or clicks or some other metric. Note that the need to run costly experiments is what specifies experimental optimization methods as a subset of optimization methods more generally.\\n\\nIn this chapter, we\\u2019ll discuss engineering workflows for each of the engineer types listed earlier\\u2014machine learning engineer (MLE), quant, and software engineer (SWE). We\\u2019ll see what kinds of systems they work on, the business metrics they measure, and how each stage of the generic workflow is implemented.\\n\\nIn your organization, you might hear of alternative ways of evaluating changes to a system. Common suggestions are domain knowledge, model-based estimates, and simulation. We\\u2019ll discuss the reason why these tools, while valuable, can\\u2019t substitute for an experimental measurement.\\n\\n1.1 Examples of engineering workflows\\n\\nWhile the engineers listed earlier may work in different domains, their overall workflows are similar. Their workflows can be seen as specific cases of the common engineering workflow we described in figure 1.1: implement change, evaluate offline, measure online. Let\\u2019s look in detail at an example workflow for an MLE, for a quant, and for an SWE.\\n\\n1.1.1 Machine learning engineer\\u2019s workflow\\n\\nImagine an MLE who works on a web-based news site. Their workflow might look like figure 1.2.\\n\\nFigure 1.2 Example workflow for a machine learning engineer building a news-based website. The site contains an ML component that predicts clicks on news articles. (1) The MLE fits a new predictor. (2) An estimate of ad revenue from the new predictor is made using logs of user clicks and ad rates. (3) The new predictor is deployed to production and actual ad revenue is measured. If it improves ad revenue, then it is accepted into the system.\\n\\nThe key machine learning component of the website is a predictor model that predicts which news articles a user will click on. The predictor might take as input many features, such as information about the user\\u2019s demographics, the user\\u2019s previous activity on the website, and information about the news article\\u2019s title or its content. The predictor\\u2019s output will be an estimate of the probability that a specific user will click on a given news article. The website could use those predictions to rank and sort news articles on a headlines-summary page hoping to put more appealing news higher up on the page.\\n\\nFigure 1.2 depicts the workflow for this system. When the MLE comes up with an idea to improve the predictor\\u2014a new feature or a new model type\\u2014the idea is subjected to the workflow:\\n\\n1. Implement change\\u2014The MLE fits the new predictor to logged data. If it produces better predictions on the logged data than the previous predictor, it passes to the next stage.\\n2. Evaluate offline\\u2014The business goal is to increase revenue from ads that run on the website, not simply to improve click predictions. Translating improved predictions into improved revenue is not straightforward, but methods exist that give useful estimates for some systems. If the estimates do not look very bad, the predictor will pass on to the next stage.\\n3. Measure online\\u2014The MLE deploys the predictor to production, and real users see their headlines ranked with it. The MLE measures the ad revenue and compares it to the ad revenue produced by the old predictor. If the new predictor improves ad revenue, then it is accepted into the system.\\n\\nA news-based website may have many other components besides a click predictor. Each of those components would be exposed to the same workflow as the predictor, ensuring that the system steadily produces more ad revenue.\\n\\nMLEs work on many kinds of systems. Sorting news headlines by click probability is an example of a broader class of system called a recommender system. Recommender systems are used to rank videos, music, social media posts, consumer goods, and more. Search engines are a similar ML system, in that they may rank search results specifically for the user. Targeted advertising, which chooses ads specifically for the user, is another type of MLE system. Now let\\u2019s turn to finance and see how quants follow the same workflow pattern.\\n\\n1.1.2 Quantitative trader\\u2019s workflow\\n\\nA quant\\u2019s workflow is very similar to the MLE\\u2019s workflow. Only the details change. There\\u2019s a different prediction to be made, for example. See figure 1.3.\\n\\nFigure 1.3 Example workflow for a quant designing an automated trading strategy. The strategy contains a price-change predictor. (1) The quant produces a new predictor. (2) Profit and risk estimates come from a simulation using historical market data. (3) Live trading measures the true profit and risk. If the new predictor increases profit and/or reduces risk, then it is accepted into the system.\\n\\nThis quant is building an automated trading strategy. It is a piece of software that issues BUY and SELL orders to an exchange hoping to, as they say, buy low and sell high. A key component is a model that predicts change in the price of the financial instrument (e.g., a stock) being traded. If the price is predicted to increase, it\\u2019s a good time to issue a BUY order. Similarly, if the price is predicted to decrease, it\\u2019s a good time to SELL. The business metric for this system is profit. But it\\u2019s also risk. Quants want both higher profit and lower risk. It is not uncommon (in practice, it\\u2019s the norm) to be concerned with more than one business metric when optimizing a system. Chapter 7, section 3 will discuss this important practical point in detail.\\n\\nFigure 1.3 shows the quant\\u2019s workflow. Changes to the trading strategy pass through these stages:\\n\\n1. Implement change\\u2014The quant fits the new price-change predictor to historical market data and verifies that it produces better predictions than the previous predictor.\\n2. Evaluate offline\\u2014Better price predictions do not guarantee higher profits (or lower risk). The full trading strategy\\u2014predictor, BUY/SELL orders, and so on\\u2014is run through a simulation (also called a backtest) on historical market data. The simulation generates predictions and mimics buying and selling to estimate profit and risk. Sufficient improvement in the strategy will allow the predictor to pass to the next stage.\\n3. Measure online\\u2014The predictor is deployed to live trading, where orders are placed and money and stock shares change hands. Only live trading can tell the true profit and risk of the strategy. The change to the predictor will be reverted if it worsens the strategy\\u2019s profit or risk.\\n\\nQuants typically work on one of two types of trading systems: principal or agency. A principal strategy trades directly for the profit of the operator (the quant, or the company employing the quant). An agency strategy trades on behalf of customers as a service, helping customers reduce their trading costs.\\n\\nThere are many variations to these two types of strategies. They may trade stocks, futures contracts, options, or many other financial products. Each product type typically has multiple exchanges around the world on which to trade.\\n\\nAlso, a key defining component of a strategy is its timescale. A principal strategy owns a stock (or other instrument) for some amount of time before selling it. That amount of time may be on the order of minutes, hours, days, or weeks. Sometimes even as long as months or as short as seconds. Each timescale requires a different predictor and a different understanding of risk.\\n\\nThe MLE and quant workflows are similar because their systems are similar. They typically consist of a predictive model fit on data and some decision-making code that determines how the prediction is used. A software engineer\\u2019s workflow is somewhat different and is the next topic.\\n\\n1.1.3 Software engineer\\u2019s workflow\\n\\nSWEs work on a broad range of systems. In this text, we\\u2019ll define SWE problems as those that do not involve building models from data (thus differentiating them from MLEs and quants). SWEs build compilers, caching systems, web servers, trading system infrastructure (on which trading strategies run), and much more.\\n\\nAs an example, let\\u2019s consider the problem of improving the response time of a search engine with the goal of lowering the \\u201cbounce rate,\\u201d which is the probability that a user will navigate away from a website after seeing just one page. Figure 1.4 shows the SWE\\u2019s workflow.\\n\\nFigure 1.4 Example workflow for a software engineer building a search engine server. The server queries, aggregates, and transforms relevant data before sending the user a response. (1) The SWE changes the transformation portion of the code. (2) They time the code offline, verifying that it takes less time than the old code to transform several test data sets. (3) Running in production, the SWE measures whether the use of this new code results in a lower bounce rate, the business-relevant metric. If so, the new code is accepted as a permanent part of the system.\\n\\nThis SWE has built a search engine. It is a web server that responds to a user\\u2019s request by querying internal sources for a data set, transforming that data set, and delivering a formatted response to the user. Users are very sensitive to the time it takes for a web server to respond. If it takes too long, a user may navigate away from the web page before the response is delivered.\\n\\nWhile there are many ways to slow down a web server\\u2019s response (slow browser, slow network, cache misses, etc.), this SWE has a hypothesis that it\\u2019s the data transformation step that is too slow. To fix the problem, they subject their hypothesis to the workflow:\\n\\n1. Implement change\\u2014The SWE implements a code change that they expect to speed up the transformation step.\\n2. Evaluate offline\\u2014This code is run and timed offline on many samples of the internal data sets that resulted from previous user requests. If it proves to be faster, it passes to the next stage.\\n3. Measure online\\u2014The code change is deployed to production where responses are served to real users. The SWE measures the bounce rate and compares it to the bounce rate before the code change. If the new code lowers the bounce rate, it is accepted as a permanent part of the system.\\n\\nEngineering teams tend to generate many creative ideas for improving the system they work on. If these ideas are the raw material, the workflow is the factory that processes them\\u2014steadily and reliably\\u2014into system improvements.\\n\\nEach pass through the workflow ends with an online measurement of business metrics. That measurement is taken via an experiment on a live production system.\\n\\n1.2 Measuring by experiment\\n\\nThe engineered systems encountered in trading and technology are complex. This complexity can make it difficult to measure the impact of changes made to them. Consider a website that sells a product. A useful business metric might be daily revenue, the total number of dollars paid to the company by customers each day. That number depends on the quality of the product, its competition, how many people know about the product, how many people have already bought it, whether people are more inclined to shop on a given day (e.g., is it a weekend? Is it Black Friday?), how easy it is to navigate and understand the website, and so on. Many, many factors affect daily revenue, and many of them are not under the control of the company.\\n\\nIf you were to make a change to this website and record a day\\u2019s revenue, how could you say whether the change improved that revenue? Would you have made more or less on the day you measured if you hadn\\u2019t made the change? More importantly, would you expect to make more or less in the future if you left the change in or took it out? These questions can be answered by running experiments.\\n\\n1.2.1 Experimental methods\\n\\nExperimental methods ignore all the other factors that affect a business metric and tease out just the impact of the change you made to the system. Surprisingly, satisfyingly, experiments even account for the impact of the factors that are unknown to you, the engineer (chapter 2 discusses this in detail). It\\u2019s this ability to isolate the impact of your system change and ignore everything else that makes an experiment the right tool for the job of measuring business impact.\\n\\nExperiments are indeed valuable, but that value comes at a cost. Experiments take time to run, and they risk generating suboptimal system performance (e.g., if the change the engineer just implemented makes things worse instead of better) or damaging it (e.g., due to a bug in the new code). To get the most out of experimentation, we\\u2019ll try to minimize these costs. Chapter 2 presents the idea of experiment design, where we minimize the amount of time an experiment will take to run while still giving the results we need. The subsequent chapters on experimental methods, chapters 3 through 6, all discuss ways to reduce these costs further in specific situations. Chapters 3 and 5, which cover bandit algorithms, make the experiment design adaptive, so that while the experiment is running and collecting measurements, the design steadily improves.\\n\\nRecall that some system changes require the measurement of business metrics for multiple configurations to discover which is best. This induces a high measurement cost. The methods of chapters 4 and 6\\u2014response surface methodology and Bayesian optimization, respectively\\u2014use statistical inference to make good guesses about which system configurations are most promising, thus reducing the total number of measurements needed to find the best configuration.\\n\\nThese methods have been used in industry anywhere from 10 to 70 years (depending on the method) and are popular in the fields in which I work\\u2014quantitative trading and social media. What makes trading and technology so amenable to experimentation is that systems in these industries have many interactions with the world. Trading systems can send thousands or tens of thousands of orders per day. Websites may have from thousands to billions (for the largest websites) of requests per day. Each interaction provides an opportunity to experiment.\\n\\nDrawing on personal experience, discussions with colleagues, and interviews specifically for the preparation of this book, I have tried to limit the material to a set of methods proven to work well in practice. Along with explanations of methods and real-world examples, I\\u2019ve also collected practical problems and pitfalls.\\n\\n1.2.2 Practical problems and pitfalls\\n\\nAll these experimental methods assume you know your business metric. Chapter 7 discusses how to define one and how there\\u2019s usually more than one to consider. It also looks more closely at how to interpret experiment results and how that may be complicated when there are multiple metrics and multiple decision-makers involved.\\n\\nFinally, chapter 8 lists ways in which real-world data can deviate from the assumptions made in the development of the experimental methods and common sources of error in interpretation of results.\\n\\nOne practical problem worth addressing before even getting into the details of experimentation is the question of whether you should experiment at all. It takes time and effort to build the tools needed to design, measure, and analyze changes to your system. You should get something in return for all that work. The next section discusses some common arguments against experimentation and presents counterarguments.\\n\\n1.3 Why are experiments necessary?\\n\\nAny SWE is likely familiar with the admonition, attributed to Donald Knuth, that \\u201cpremature optimization is the root of all evil\\u201d\\u2014that is, rather than implement ideas that you expect will make your code run faster (or better in some other way) at the outset, first write simple code to solve the problem, devise a way to time the code, then test your ideas one at a time to see which ones actually speed things up. It\\u2019s too difficult to reason about everything that could affect speed\\u2014the whole code base, the computer architecture, the operating system, and so on\\u2014all at once, so you rely on a test.\\n\\nSimilar reasoning applies to improving business metrics. There are too many factors that could affect business metrics for a web product, including all the software engineering factors listed above, as well as data quality, model quality, changes in user sentiment, changes in browser technology, news of the day, and much more. This is the case for any engineered system: many factors affect business metrics, and they do so in complicated ways. Experimentation is necessary to accurately measure the impact on business metrics of a change to the system.\\n\\nThere are other tools available to assess the business-metric impact of a system change. Some examples are\\n\\n1. Domain knowledge\\n2. Offline model quality\\n3. Simulation\\n\\nThese tools are discussed in detail below. You\\u2019ll see that they have two things in common: (1) they are cheaper (less resource-intensive) to use, and (2) they are less accurate than an experimental result. These tools may be useful supplements to your decision-making, but they can\\u2019t replace experiments.\\n\\n1.3.1 Domain knowledge\\n\\nDomain knowledge is the specialized knowledge of a field, a market, or a business that people acquire through education and experience. You might think this kind of knowledge would make people good at predicting which new ideas will make a positive business impact. But for the past 10 years, I\\u2019ve given an informal survey to my quant coworkers. I\\u2019ve asked, \\u201cOf the ideas you\\u2019ve implemented and tested, how many have actually worked?\\u201d The answer every single time has been 1 in 10. And it\\u2019s always been said with a chuckle and an air of resignation. That survey isn\\u2019t exactly scientific, but similar stories come from elsewhere, too. Microsoft reports that only one-third of experiments improve metrics. Amazon reports a success rate below 50%. Netflix says only 10%. Even though the people generating the ideas had domain knowledge, most experiments failed to produce the expected results. There seem to be aspects of the world that keep most good ideas from working.\\n\\nOne aspect is complexity. Your system is likely made up of many components: hardware components like computers and network switches, software components (both in-house and third-party), and human elements\\u2014operators, suppliers, customers. These components interact with each other, with the physical environment, and with society at large. Computers interact via networks. Humans interact with each other online and in person. They also interact with your servers through a browser or an API.\\n\\nThe physical environment includes the temperature of a data center\\u2014which, when too high, adversely impacts computer performance or causes failure. It also includes the weather, which affects people\\u2019s behavior. When the weather\\u2019s bad, do people use your product more because they can\\u2019t engage in outdoor activities? Do their posts or comments reflect their mood, which is in turn affected by the weather? There is evidence that sunshine in the morning in New York City is correlated with increased stock returns on that day on the New York Stock Exchange. The proposed causal mechanism is that sunshine makes the traders more optimistic. No engineer\\u2014or anyone, for that matter\\u2014could be expected to anticipate effects like this just from experience or reasoning.\\n\\nTo put a finer point on it, if you have N components in your system, you have ~N^2 pair-wise interactions. In other words, if your system has many components, then it has a huge number of interactions. That\\u2019s too much for a person to consider when trying to guess the impact a system change will have on business metrics.\\n\\nGenerally, we\\u2019ll ignore most of that complexity when reasoning about a system in order to make things more manageable. We\\u2019ll create a mental model or even a mathematical model. In either case, the model of how your system operates contains the information about the system that you deemed important enough to include. In some models, this information might be called the signal. You leave out irrelevant details, which you might call noise. There\\u2019s a third category of things that affect your system\\u2019s performance: the things you didn\\u2019t even consider, because you don\\u2019t know about them. The \\u201cunknown unknowns,\\u201d they\\u2019re sometimes called. These things could affect experimental results by any amount, either positively or negatively. You won\\u2019t anticipate them or have intuition about them because they\\u2019re missing from your model.\\n\\nIt\\u2019s plausible that the \\u201cunknown unknowns\\u201d of your system might include its most valuable aspects. A Harvard Business Review article tells the story of a proposed change to Microsoft\\u2019s Bing search engine. A domain knowledge-based decision made the change a low priority for implementation, but when it was finally coded up and put into production, it had a tremendous positive impact on revenue (over $100 million per year). It was simply the case that no one could understand the system\\u2014the code, the design, the users, and so on\\u2014completely enough to predict the dramatic impact of that change. Not because they weren\\u2019t smart. Not because they weren\\u2019t knowledgeable. Just because Bing, the user base, and the world they interact with are collectively just too complex.\\n\\nIf your company is competitive and surviving, there\\u2019s a good chance your \\u201cunknown unknowns\\u201d overlap with your competitors\\u2019. If that\\u2019s the case, then to do something novel\\u2014to find value where your competitors haven\\u2019t\\u2014you\\u2019ll need to make changes to your system that you can\\u2019t evaluate with your existing domain knowledge. You\\u2019ll need to run experiments instead.\\n\\nDomain knowledge is valuable. It will help you generate ideas and prioritize them\\u2014to make good bets. But domain knowledge won\\u2019t tell you outcomes. To understand impact on business metrics, you need to take experimental measurements. In addition, I posit that the most valuable changes you make to your system may come as surprises, creating impact unpredicted by domain knowledge.\\n\\n1.3.2 Offline model quality\\n\\nIt is common practice among MLEs to include a prediction model (e.g., a classifier) as a component in a system. It is not an uncommon experience to improve a model\\u2019s fit-quality metric (e.g., cross-entropy) and yet not see the business metric improve when the model is deployed.\\n\\nLet\\u2019s say you build a model that predicts whether a user will click on news articles about sports. You gather a data set from production logs. It contains examples of sports articles that were presented to a user along with a record of which articles the user clicked on. Your model analyzes each article\\u2019s headline and predicts clicks very well. When you\\u2019re done building your model, you test it on out-of-sample data\\u2014data that wasn\\u2019t used in the fitting process\\u2014just to be sure you didn\\u2019t overfit. The model works great.\\n\\nNext you put your model into production like this: Every time a user loads the sports news page, you sort the articles by your model\\u2019s prediction, hoping to show the articles the user is more interested in nearer to the top of the list. You find that the user isn\\u2019t more likely to click on the articles near the top. In fact, your model no longer seems to predict clicks very well. The model wasn\\u2019t overfit. You checked for that. It\\u2019s something different. The data used to fit your model was missing counterfactuals\\u2014events that happen in your system after you deploy a change but that didn\\u2019t happen before deployment.\\n\\nThe historical data you used to fit the model was generated by the system without your model in it. The articles were sorted some other way (perhaps sorted by date, or maybe using a different click-prediction model). When you fit your model, you were teaching it how users responded to that old system, the one with the old sorting method. Users responded differently to the new sorting method. It is difficult, if not impossible, to predict exactly how users will respond to the deployment of a new model.\\n\\nThe same experience might be had by a quant. They could build a new price-change prediction model using a regression, find that it has a higher R^2 (a common measure of the quality of a fit) than their old model, and works well out-of-sample, but still, when deployed, the profit of the strategy does not improve. The market is made up of traders\\u2014some algorithmic, some human\\u2014and they will respond differently to the new model\\u2019s presence in the market than they did to the old model\\u2019s. In this case, during fitting, the quant taught the new model about the old market, the one in which the new model was not a participant.\\n\\nThis is such a common experience that most quants and MLEs will (eventually) be familiar with it. The Facebook ML Field Guide, episode 6 refers to this problem as the \\u201conline-offline gap.\\u201d The only way to be sure you\\u2019ve improved the system is to run the final stage of the workflow, the online measurement.\\n\\n1.3.3 Simulation\\n\\nSimulations are tools that estimate a system\\u2019s business metrics offline. They might combine logged data, models of users or markets, scientific models, or heuristics. They can vary considerably in their form from domain to domain.\\n\\nSimulations differ from the simple fitting metrics (cross-entropy or R^2) discussed in the previous section. Simulations typically account for all components of a system and aim to produce numbers like revenue or user engagement that may be compared to the numbers that come from experimental measurements.\\n\\nFor example, a standard quant\\u2019s tool is a trading simulation. Offline, it runs historical market data\\u2014trades and quotes\\u2014through the same trading strategy code that is used in production. When that strategy asks to execute a trade, the simulator mimics the behavior of the market using heuristics or a model of the market. From this simulation, a quant can estimate profit, risk, shares traded, and other useful business metrics.\\n\\nSimulations can give more precise answers\\u2014meaning numbers with smaller error bars\\u2014than experiments because they can use much more data. For example, a single simulation might process 1 month to 10 years of data, depending on the timescale over which the strategy trades, in a single run. This simulation might take minutes to hours to run, depending on the complexity of the strategy. An experiment, on the other hand, that takes a measurement with 1 month of data needs to run for 1 month. Want 10 years of experimental data? You\\u2019ll wait 10 years.\\n\\nSimulations may also be run multiple times on the same data set. Each run could try slight variations on the same strategy and allow the quant to choose the best one\\u2014the one with the best profit-to-risk tradeoff, for example\\u2014to trade in production. With experiments multiple runs are impossible. You can\\u2019t trade for a month, say, then \\u201crewind\\u201d real life and trade again with a different strategy. There are effective ways to compare different strategies experimentally, but the process is orders of magnitude faster in simulation.\\n\\nSimulations may be more precise and faster, but experiments are more accurate. Simulations might be biased (inaccurate) because of missing counterfactuals, just like prediction models. What happens, for example, when a trading strategy sends an order to an exchange? It might show up in the market, and other traders will see and respond to it. This changes future market data, which is then seen by the trading strategy and used for its decisions, and so on. Other traders\\u2019 real responses to our actions simply don\\u2019t exist in simulation.\\n\\nMLEs use simulation, too. Engineers working on Facebook Feed use a simulator that replays logged data through the Feed code that estimates users\\u2019 responses. In \\u201cCombining online and offline tests to improve News Feed ranking,\\u201d they note that their offline simulations are biased. While the simulation results are related to real results, they don\\u2019t match exactly and the relationship between them is nontrivial. (The blog post goes on to design a model-based mapping from simulation results to experimental results.)\\n\\nResearchers who study a field called evolutionary robotics design robot controllers\\u2014pieces of code that take in sensor information and output commands to a robot\\u2019s actuators\\u2014using algorithms inspired by evolution. The evolutionary algorithms search for controller parameters that optimize the performance of the robot as measured by a simulation. The researchers notice so often that controllers designed in simulation don\\u2019t work on real robots that they have coined a term for this effect: the reality gap.\\n\\nIn a live-streamed event, Tesla Autonomy Day, CEO Elon Musk is asked why Tesla relies so much on data collected from real drivers instead of training their autonomous driving controller via simulation. He says that they do use simulation, but that since they \\u201cdon\\u2019t know what they don\\u2019t know\\u201d\\u2014and all of what they don\\u2019t know would be missing from the simulation\\u2014they invest effort and money into collecting lots of real data. In the same video, AI director Andrej Karpathy gives several examples of rare, unanticipated images from around the world that need to be interpreted by their vision system. Without appealing to real-world data, their system would never learn to deal with these images.\\n\\nSimulation is a powerful offline design tool. Simulations can be used in the second stage of the workflow to generate estimates of business metrics. Because they tend to be biased, and you can never know exactly how, it is always necessary to test changes to your system with an experiment.\\n\\n1 Summary\\n\\n1. Experimental optimization is the process of improving an engineered system using measurement-based design decisions.\\n2. Experimental methods minimize the time and risk associated with experimental measurements.\\n3. Experiments are the most accurate way to measure the impact on business metrics of changes to an engineered system.\\n4. Domain knowledge, prediction models, and simulation are powerful supplements to experiments but are not replacements for them.\", \"refusal\": null, \"role\": \"assistant\", \"annotations\": [], \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1756932450, \"model\": \"gpt-5-mini-2025-08-07\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 6877, \"prompt_tokens\": 12900, \"total_tokens\": 19777, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Cost: $0.016978999999999998\n",
      "Input tokens: 12900\n",
      "Output tokens: 6877\n",
      "Speaker 1: 1 Optimizing systems by experiment\n",
      "\n",
      "Speaker 1: This chapter covers\n",
      "\n",
      "Speaker 1: 1. Optimizing an engineered system\n",
      "Speaker 1: 2. Exploring what experiments are\n",
      "Speaker 1: 3. Learning why experiments are uniquely valuable\n",
      "\n",
      "Speaker 1: The past 20 years have seen a surge in interest in the development of experimental methods used to measure and improve engineered systems, such as web products, automated trading systems, and software infrastructure. Experimental methods have become more automated and more efficient. They have scaled up to large systems like search engines or social media sites. These methods generate continuous, automated performance improvement of live production systems.\n",
      "\n",
      "Speaker 1: Using these experimental methods, engineers measure the business impact of the changes they make to their systems and determine the optimal settings under which to run them. We call this process experimental optimization.\n",
      "\n",
      "Speaker 1: This book teaches several experimental optimization methods used by engineers working in trading and technology. We’ll discuss systems built by three specific types of engineers:\n",
      "\n",
      "Speaker 1: 1. Machine learning engineers\n",
      "Speaker 1: 2. Quantitative traders (“quants”)\n",
      "Speaker 1: 3. Software engineers\n",
      "\n",
      "Speaker 1: Machine learning engineers often work on web products like search engines, recommender systems, and ad placement systems. Quants build automated trading systems. Software engineers build infrastructure and tooling such as web servers, compilers, and event processing systems.\n",
      "\n",
      "Speaker 1: These engineers follow a common process, or workflow, that is an endless loop of steady system improvement. Figure 1.1 shows this common workflow.\n",
      "\n",
      "Speaker 1: Figure 1.1 Common engineering workflow. (1) A new idea is first implemented as a code change to the system. (2) Typically, some offline evaluation is performed that rejects ideas that are expected to negatively impact business metrics. (3) The change is pushed into the production system, and business metrics are measured there, online. Accepted changes become permanent parts of the system. The whole workflow repeats, creating reliable, continuous improvement of the system.\n",
      "\n",
      "Speaker 1: The common workflow creates progressive improvement of an engineered system. An individual or a team generates ideas that they expect will improve the system, and they pass each idea through the workflow. Good ideas are accepted into the system, and bad ideas are rejected:\n",
      "\n",
      "Speaker 1: 1. Implement change—First, an engineer implements an idea as a code change, an update to the system’s software. In this stage, the code is subjected to typical software engineering quality controls, like code review and unit testing. If it passes all tests, it moves on to the next stage.\n",
      "Speaker 1: 2. Evaluate offline—The business impact of the code change is evaluated offline, away from the production system. This evaluation typically uses data previously logged by the production system to produce rough estimates of business metrics such as revenue or the expected number of clicks on an advertisement. If these estimates show that applying this code change to the production system would worsen business metrics, then the code change is rejected. Otherwise, it is passed to the final stage.\n",
      "Speaker 1: 3. Measure online—The change is pushed into production, where its impact on business metrics is measured. The code change might require some configuration—the setting of numerical parameters or Boolean flags. If so, the engineer will measure business metrics for multiple configurations to determine which is best. If no improvements to business metrics can be made by applying (and configuring) this code change, then the code change is rejected. Otherwise, the change is made permanent and the system improves.\n",
      "\n",
      "Speaker 1: This book deals with the final stage, “measure online.” In this stage, you run an experiment on the live production system. Experimentation is valuable because it produces a measurement from the real system, which is information you couldn’t get any other way. But experimentation on a live system takes time. Some experiments take days or weeks to run. And it is not without risk. When you run an experiment, you may lose money, alienate users, or generate bad press or social media chatter as users notice and complain about the changes you’re making to your system. Therefore, you need to take measurements as quickly and precisely as possible to minimize the ill effects of ideas—call them costs for brevity—that don’t work and to take maximal advantage of ones that do.\n",
      "\n",
      "Speaker 1: To extract the most value from a new bit of code, you need to configure it optimally. You could liken the process of finding the best configuration to tuning an old AM or FM radio or tuning a guitar string. You typically turn a knob up and down and listen to see whether you’re getting good results. Set the knob too high or too low and your radio will be noisy, or your guitar will be sharp or flat. So it is with code configuration parameters (often referred to as knobs in code your author has read). You want them set to just the right values to give maximal business impact—whether that’s revenue or clicks or some other metric. Note that the need to run costly experiments is what specifies experimental optimization methods as a subset of optimization methods more generally.\n",
      "\n",
      "Speaker 1: In this chapter, we’ll discuss engineering workflows for each of the engineer types listed earlier—machine learning engineer (MLE), quant, and software engineer (SWE). We’ll see what kinds of systems they work on, the business metrics they measure, and how each stage of the generic workflow is implemented.\n",
      "\n",
      "Speaker 1: In your organization, you might hear of alternative ways of evaluating changes to a system. Common suggestions are domain knowledge, model-based estimates, and simulation. We’ll discuss the reason why these tools, while valuable, can’t substitute for an experimental measurement.\n",
      "\n",
      "Speaker 1: 1.1 Examples of engineering workflows\n",
      "\n",
      "Speaker 1: While the engineers listed earlier may work in different domains, their overall workflows are similar. Their workflows can be seen as specific cases of the common engineering workflow we described in figure 1.1: implement change, evaluate offline, measure online. Let’s look in detail at an example workflow for an MLE, for a quant, and for an SWE.\n",
      "\n",
      "Speaker 1: 1.1.1 Machine learning engineer’s workflow\n",
      "\n",
      "Speaker 1: Imagine an MLE who works on a web-based news site. Their workflow might look like figure 1.2.\n",
      "\n",
      "Speaker 1: Figure 1.2 Example workflow for a machine learning engineer building a news-based website. The site contains an ML component that predicts clicks on news articles. (1) The MLE fits a new predictor. (2) An estimate of ad revenue from the new predictor is made using logs of user clicks and ad rates. (3) The new predictor is deployed to production and actual ad revenue is measured. If it improves ad revenue, then it is accepted into the system.\n",
      "\n",
      "Speaker 1: The key machine learning component of the website is a predictor model that predicts which news articles a user will click on. The predictor might take as input many features, such as information about the user’s demographics, the user’s previous activity on the website, and information about the news article’s title or its content. The predictor’s output will be an estimate of the probability that a specific user will click on a given news article. The website could use those predictions to rank and sort news articles on a headlines-summary page hoping to put more appealing news higher up on the page.\n",
      "\n",
      "Speaker 1: Figure 1.2 depicts the workflow for this system. When the MLE comes up with an idea to improve the predictor—a new feature or a new model type—the idea is subjected to the workflow:\n",
      "\n",
      "Speaker 1: 1. Implement change—The MLE fits the new predictor to logged data. If it produces better predictions on the logged data than the previous predictor, it passes to the next stage.\n",
      "Speaker 1: 2. Evaluate offline—The business goal is to increase revenue from ads that run on the website, not simply to improve click predictions. Translating improved predictions into improved revenue is not straightforward, but methods exist that give useful estimates for some systems. If the estimates do not look very bad, the predictor will pass on to the next stage.\n",
      "Speaker 1: 3. Measure online—The MLE deploys the predictor to production, and real users see their headlines ranked with it. The MLE measures the ad revenue and compares it to the ad revenue produced by the old predictor. If the new predictor improves ad revenue, then it is accepted into the system.\n",
      "\n",
      "Speaker 1: A news-based website may have many other components besides a click predictor. Each of those components would be exposed to the same workflow as the predictor, ensuring that the system steadily produces more ad revenue.\n",
      "\n",
      "Speaker 1: MLEs work on many kinds of systems. Sorting news headlines by click probability is an example of a broader class of system called a recommender system. Recommender systems are used to rank videos, music, social media posts, consumer goods, and more. Search engines are a similar ML system, in that they may rank search results specifically for the user. Targeted advertising, which chooses ads specifically for the user, is another type of MLE system. Now let’s turn to finance and see how quants follow the same workflow pattern.\n",
      "\n",
      "Speaker 1: 1.1.2 Quantitative trader’s workflow\n",
      "\n",
      "Speaker 1: A quant’s workflow is very similar to the MLE’s workflow. Only the details change. There’s a different prediction to be made, for example. See figure 1.3.\n",
      "\n",
      "Speaker 1: Figure 1.3 Example workflow for a quant designing an automated trading strategy. The strategy contains a price-change predictor. (1) The quant produces a new predictor. (2) Profit and risk estimates come from a simulation using historical market data. (3) Live trading measures the true profit and risk. If the new predictor increases profit and/or reduces risk, then it is accepted into the system.\n",
      "\n",
      "Speaker 1: This quant is building an automated trading strategy. It is a piece of software that issues BUY and SELL orders to an exchange hoping to, as they say, buy low and sell high. A key component is a model that predicts change in the price of the financial instrument (e.g., a stock) being traded. If the price is predicted to increase, it’s a good time to issue a BUY order. Similarly, if the price is predicted to decrease, it’s a good time to SELL. The business metric for this system is profit. But it’s also risk. Quants want both higher profit and lower risk. It is not uncommon (in practice, it’s the norm) to be concerned with more than one business metric when optimizing a system. Chapter 7, section 3 will discuss this important practical point in detail.\n",
      "\n",
      "Speaker 1: Figure 1.3 shows the quant’s workflow. Changes to the trading strategy pass through these stages:\n",
      "\n",
      "Speaker 1: 1. Implement change—The quant fits the new price-change predictor to historical market data and verifies that it produces better predictions than the previous predictor.\n",
      "Speaker 1: 2. Evaluate offline—Better price predictions do not guarantee higher profits (or lower risk). The full trading strategy—predictor, BUY/SELL orders, and so on—is run through a simulation (also called a backtest) on historical market data. The simulation generates predictions and mimics buying and selling to estimate profit and risk. Sufficient improvement in the strategy will allow the predictor to pass to the next stage.\n",
      "Speaker 1: 3. Measure online—The predictor is deployed to live trading, where orders are placed and money and stock shares change hands. Only live trading can tell the true profit and risk of the strategy. The change to the predictor will be reverted if it worsens the strategy’s profit or risk.\n",
      "\n",
      "Speaker 1: Quants typically work on one of two types of trading systems: principal or agency. A principal strategy trades directly for the profit of the operator (the quant, or the company employing the quant). An agency strategy trades on behalf of customers as a service, helping customers reduce their trading costs.\n",
      "\n",
      "Speaker 1: There are many variations to these two types of strategies. They may trade stocks, futures contracts, options, or many other financial products. Each product type typically has multiple exchanges around the world on which to trade.\n",
      "\n",
      "Speaker 1: Also, a key defining component of a strategy is its timescale. A principal strategy owns a stock (or other instrument) for some amount of time before selling it. That amount of time may be on the order of minutes, hours, days, or weeks. Sometimes even as long as months or as short as seconds. Each timescale requires a different predictor and a different understanding of risk.\n",
      "\n",
      "Speaker 1: The MLE and quant workflows are similar because their systems are similar. They typically consist of a predictive model fit on data and some decision-making code that determines how the prediction is used. A software engineer’s workflow is somewhat different and is the next topic.\n",
      "\n",
      "Speaker 1: 1.1.3 Software engineer’s workflow\n",
      "\n",
      "Speaker 1: SWEs work on a broad range of systems. In this text, we’ll define SWE problems as those that do not involve building models from data (thus differentiating them from MLEs and quants). SWEs build compilers, caching systems, web servers, trading system infrastructure (on which trading strategies run), and much more.\n",
      "\n",
      "Speaker 1: As an example, let’s consider the problem of improving the response time of a search engine with the goal of lowering the “bounce rate,” which is the probability that a user will navigate away from a website after seeing just one page. Figure 1.4 shows the SWE’s workflow.\n",
      "\n",
      "Speaker 1: Figure 1.4 Example workflow for a software engineer building a search engine server. The server queries, aggregates, and transforms relevant data before sending the user a response. (1) The SWE changes the transformation portion of the code. (2) They time the code offline, verifying that it takes less time than the old code to transform several test data sets. (3) Running in production, the SWE measures whether the use of this new code results in a lower bounce rate, the business-relevant metric. If so, the new code is accepted as a permanent part of the system.\n",
      "\n",
      "Speaker 1: This SWE has built a search engine. It is a web server that responds to a user’s request by querying internal sources for a data set, transforming that data set, and delivering a formatted response to the user. Users are very sensitive to the time it takes for a web server to respond. If it takes too long, a user may navigate away from the web page before the response is delivered.\n",
      "\n",
      "Speaker 1: While there are many ways to slow down a web server’s response (slow browser, slow network, cache misses, etc.), this SWE has a hypothesis that it’s the data transformation step that is too slow. To fix the problem, they subject their hypothesis to the workflow:\n",
      "\n",
      "Speaker 1: 1. Implement change—The SWE implements a code change that they expect to speed up the transformation step.\n",
      "Speaker 1: 2. Evaluate offline—This code is run and timed offline on many samples of the internal data sets that resulted from previous user requests. If it proves to be faster, it passes to the next stage.\n",
      "Speaker 1: 3. Measure online—The code change is deployed to production where responses are served to real users. The SWE measures the bounce rate and compares it to the bounce rate before the code change. If the new code lowers the bounce rate, it is accepted as a permanent part of the system.\n",
      "\n",
      "Speaker 1: Engineering teams tend to generate many creative ideas for improving the system they work on. If these ideas are the raw material, the workflow is the factory that processes them—steadily and reliably—into system improvements.\n",
      "\n",
      "Speaker 1: Each pass through the workflow ends with an online measurement of business metrics. That measurement is taken via an experiment on a live production system.\n",
      "\n",
      "Speaker 1: 1.2 Measuring by experiment\n",
      "\n",
      "Speaker 1: The engineered systems encountered in trading and technology are complex. This complexity can make it difficult to measure the impact of changes made to them. Consider a website that sells a product. A useful business metric might be daily revenue, the total number of dollars paid to the company by customers each day. That number depends on the quality of the product, its competition, how many people know about the product, how many people have already bought it, whether people are more inclined to shop on a given day (e.g., is it a weekend? Is it Black Friday?), how easy it is to navigate and understand the website, and so on. Many, many factors affect daily revenue, and many of them are not under the control of the company.\n",
      "\n",
      "Speaker 1: If you were to make a change to this website and record a day’s revenue, how could you say whether the change improved that revenue? Would you have made more or less on the day you measured if you hadn’t made the change? More importantly, would you expect to make more or less in the future if you left the change in or took it out? These questions can be answered by running experiments.\n",
      "\n",
      "Speaker 1: 1.2.1 Experimental methods\n",
      "\n",
      "Speaker 1: Experimental methods ignore all the other factors that affect a business metric and tease out just the impact of the change you made to the system. Surprisingly, satisfyingly, experiments even account for the impact of the factors that are unknown to you, the engineer (chapter 2 discusses this in detail). It’s this ability to isolate the impact of your system change and ignore everything else that makes an experiment the right tool for the job of measuring business impact.\n",
      "\n",
      "Speaker 1: Experiments are indeed valuable, but that value comes at a cost. Experiments take time to run, and they risk generating suboptimal system performance (e.g., if the change the engineer just implemented makes things worse instead of better) or damaging it (e.g., due to a bug in the new code). To get the most out of experimentation, we’ll try to minimize these costs. Chapter 2 presents the idea of experiment design, where we minimize the amount of time an experiment will take to run while still giving the results we need. The subsequent chapters on experimental methods, chapters 3 through 6, all discuss ways to reduce these costs further in specific situations. Chapters 3 and 5, which cover bandit algorithms, make the experiment design adaptive, so that while the experiment is running and collecting measurements, the design steadily improves.\n",
      "\n",
      "Speaker 1: Recall that some system changes require the measurement of business metrics for multiple configurations to discover which is best. This induces a high measurement cost. The methods of chapters 4 and 6—response surface methodology and Bayesian optimization, respectively—use statistical inference to make good guesses about which system configurations are most promising, thus reducing the total number of measurements needed to find the best configuration.\n",
      "\n",
      "Speaker 1: These methods have been used in industry anywhere from 10 to 70 years (depending on the method) and are popular in the fields in which I work—quantitative trading and social media. What makes trading and technology so amenable to experimentation is that systems in these industries have many interactions with the world. Trading systems can send thousands or tens of thousands of orders per day. Websites may have from thousands to billions (for the largest websites) of requests per day. Each interaction provides an opportunity to experiment.\n",
      "\n",
      "Speaker 1: Drawing on personal experience, discussions with colleagues, and interviews specifically for the preparation of this book, I have tried to limit the material to a set of methods proven to work well in practice. Along with explanations of methods and real-world examples, I’ve also collected practical problems and pitfalls.\n",
      "\n",
      "Speaker 1: 1.2.2 Practical problems and pitfalls\n",
      "\n",
      "Speaker 1: All these experimental methods assume you know your business metric. Chapter 7 discusses how to define one and how there’s usually more than one to consider. It also looks more closely at how to interpret experiment results and how that may be complicated when there are multiple metrics and multiple decision-makers involved.\n",
      "\n",
      "Speaker 1: Finally, chapter 8 lists ways in which real-world data can deviate from the assumptions made in the development of the experimental methods and common sources of error in interpretation of results.\n",
      "\n",
      "Speaker 1: One practical problem worth addressing before even getting into the details of experimentation is the question of whether you should experiment at all. It takes time and effort to build the tools needed to design, measure, and analyze changes to your system. You should get something in return for all that work. The next section discusses some common arguments against experimentation and presents counterarguments.\n",
      "\n",
      "Speaker 1: 1.3 Why are experiments necessary?\n",
      "\n",
      "Speaker 1: Any SWE is likely familiar with the admonition, attributed to Donald Knuth, that “premature optimization is the root of all evil”—that is, rather than implement ideas that you expect will make your code run faster (or better in some other way) at the outset, first write simple code to solve the problem, devise a way to time the code, then test your ideas one at a time to see which ones actually speed things up. It’s too difficult to reason about everything that could affect speed—the whole code base, the computer architecture, the operating system, and so on—all at once, so you rely on a test.\n",
      "\n",
      "Speaker 1: Similar reasoning applies to improving business metrics. There are too many factors that could affect business metrics for a web product, including all the software engineering factors listed above, as well as data quality, model quality, changes in user sentiment, changes in browser technology, news of the day, and much more. This is the case for any engineered system: many factors affect business metrics, and they do so in complicated ways. Experimentation is necessary to accurately measure the impact on business metrics of a change to the system.\n",
      "\n",
      "Speaker 1: There are other tools available to assess the business-metric impact of a system change. Some examples are\n",
      "\n",
      "Speaker 1: 1. Domain knowledge\n",
      "Speaker 1: 2. Offline model quality\n",
      "Speaker 1: 3. Simulation\n",
      "\n",
      "Speaker 1: These tools are discussed in detail below. You’ll see that they have two things in common: (1) they are cheaper (less resource-intensive) to use, and (2) they are less accurate than an experimental result. These tools may be useful supplements to your decision-making, but they can’t replace experiments.\n",
      "\n",
      "Speaker 1: 1.3.1 Domain knowledge\n",
      "\n",
      "Speaker 1: Domain knowledge is the specialized knowledge of a field, a market, or a business that people acquire through education and experience. You might think this kind of knowledge would make people good at predicting which new ideas will make a positive business impact. But for the past 10 years, I’ve given an informal survey to my quant coworkers. I’ve asked, “Of the ideas you’ve implemented and tested, how many have actually worked?” The answer every single time has been 1 in 10. And it’s always been said with a chuckle and an air of resignation. That survey isn’t exactly scientific, but similar stories come from elsewhere, too. Microsoft reports that only one-third of experiments improve metrics. Amazon reports a success rate below 50%. Netflix says only 10%. Even though the people generating the ideas had domain knowledge, most experiments failed to produce the expected results. There seem to be aspects of the world that keep most good ideas from working.\n",
      "\n",
      "Speaker 1: One aspect is complexity. Your system is likely made up of many components: hardware components like computers and network switches, software components (both in-house and third-party), and human elements—operators, suppliers, customers. These components interact with each other, with the physical environment, and with society at large. Computers interact via networks. Humans interact with each other online and in person. They also interact with your servers through a browser or an API.\n",
      "\n",
      "Speaker 1: The physical environment includes the temperature of a data center—which, when too high, adversely impacts computer performance or causes failure. It also includes the weather, which affects people’s behavior. When the weather’s bad, do people use your product more because they can’t engage in outdoor activities? Do their posts or comments reflect their mood, which is in turn affected by the weather? There is evidence that sunshine in the morning in New York City is correlated with increased stock returns on that day on the New York Stock Exchange. The proposed causal mechanism is that sunshine makes the traders more optimistic. No engineer—or anyone, for that matter—could be expected to anticipate effects like this just from experience or reasoning.\n",
      "\n",
      "Speaker 1: To put a finer point on it, if you have N components in your system, you have ~N^2 pair-wise interactions. In other words, if your system has many components, then it has a huge number of interactions. That’s too much for a person to consider when trying to guess the impact a system change will have on business metrics.\n",
      "\n",
      "Speaker 1: Generally, we’ll ignore most of that complexity when reasoning about a system in order to make things more manageable. We’ll create a mental model or even a mathematical model. In either case, the model of how your system operates contains the information about the system that you deemed important enough to include. In some models, this information might be called the signal. You leave out irrelevant details, which you might call noise. There’s a third category of things that affect your system’s performance: the things you didn’t even consider, because you don’t know about them. The “unknown unknowns,” they’re sometimes called. These things could affect experimental results by any amount, either positively or negatively. You won’t anticipate them or have intuition about them because they’re missing from your model.\n",
      "\n",
      "Speaker 1: It’s plausible that the “unknown unknowns” of your system might include its most valuable aspects. A Harvard Business Review article tells the story of a proposed change to Microsoft’s Bing search engine. A domain knowledge-based decision made the change a low priority for implementation, but when it was finally coded up and put into production, it had a tremendous positive impact on revenue (over $100 million per year). It was simply the case that no one could understand the system—the code, the design, the users, and so on—completely enough to predict the dramatic impact of that change. Not because they weren’t smart. Not because they weren’t knowledgeable. Just because Bing, the user base, and the world they interact with are collectively just too complex.\n",
      "\n",
      "Speaker 1: If your company is competitive and surviving, there’s a good chance your “unknown unknowns” overlap with your competitors’. If that’s the case, then to do something novel—to find value where your competitors haven’t—you’ll need to make changes to your system that you can’t evaluate with your existing domain knowledge. You’ll need to run experiments instead.\n",
      "\n",
      "Speaker 1: Domain knowledge is valuable. It will help you generate ideas and prioritize them—to make good bets. But domain knowledge won’t tell you outcomes. To understand impact on business metrics, you need to take experimental measurements. In addition, I posit that the most valuable changes you make to your system may come as surprises, creating impact unpredicted by domain knowledge.\n",
      "\n",
      "Speaker 1: 1.3.2 Offline model quality\n",
      "\n",
      "Speaker 1: It is common practice among MLEs to include a prediction model (e.g., a classifier) as a component in a system. It is not an uncommon experience to improve a model’s fit-quality metric (e.g., cross-entropy) and yet not see the business metric improve when the model is deployed.\n",
      "\n",
      "Speaker 1: Let’s say you build a model that predicts whether a user will click on news articles about sports. You gather a data set from production logs. It contains examples of sports articles that were presented to a user along with a record of which articles the user clicked on. Your model analyzes each article’s headline and predicts clicks very well. When you’re done building your model, you test it on out-of-sample data—data that wasn’t used in the fitting process—just to be sure you didn’t overfit. The model works great.\n",
      "\n",
      "Speaker 1: Next you put your model into production like this: Every time a user loads the sports news page, you sort the articles by your model’s prediction, hoping to show the articles the user is more interested in nearer to the top of the list. You find that the user isn’t more likely to click on the articles near the top. In fact, your model no longer seems to predict clicks very well. The model wasn’t overfit. You checked for that. It’s something different. The data used to fit your model was missing counterfactuals—events that happen in your system after you deploy a change but that didn’t happen before deployment.\n",
      "\n",
      "Speaker 1: The historical data you used to fit the model was generated by the system without your model in it. The articles were sorted some other way (perhaps sorted by date, or maybe using a different click-prediction model). When you fit your model, you were teaching it how users responded to that old system, the one with the old sorting method. Users responded differently to the new sorting method. It is difficult, if not impossible, to predict exactly how users will respond to the deployment of a new model.\n",
      "\n",
      "Speaker 1: The same experience might be had by a quant. They could build a new price-change prediction model using a regression, find that it has a higher R^2 (a common measure of the quality of a fit) than their old model, and works well out-of-sample, but still, when deployed, the profit of the strategy does not improve. The market is made up of traders—some algorithmic, some human—and they will respond differently to the new model’s presence in the market than they did to the old model’s. In this case, during fitting, the quant taught the new model about the old market, the one in which the new model was not a participant.\n",
      "\n",
      "Speaker 1: This is such a common experience that most quants and MLEs will (eventually) be familiar with it. The Facebook ML Field Guide, episode 6 refers to this problem as the “online-offline gap.” The only way to be sure you’ve improved the system is to run the final stage of the workflow, the online measurement.\n",
      "\n",
      "Speaker 1: 1.3.3 Simulation\n",
      "\n",
      "Speaker 1: Simulations are tools that estimate a system’s business metrics offline. They might combine logged data, models of users or markets, scientific models, or heuristics. They can vary considerably in their form from domain to domain.\n",
      "\n",
      "Speaker 1: Simulations differ from the simple fitting metrics (cross-entropy or R^2) discussed in the previous section. Simulations typically account for all components of a system and aim to produce numbers like revenue or user engagement that may be compared to the numbers that come from experimental measurements.\n",
      "\n",
      "Speaker 1: For example, a standard quant’s tool is a trading simulation. Offline, it runs historical market data—trades and quotes—through the same trading strategy code that is used in production. When that strategy asks to execute a trade, the simulator mimics the behavior of the market using heuristics or a model of the market. From this simulation, a quant can estimate profit, risk, shares traded, and other useful business metrics.\n",
      "\n",
      "Speaker 1: Simulations can give more precise answers—meaning numbers with smaller error bars—than experiments because they can use much more data. For example, a single simulation might process 1 month to 10 years of data, depending on the timescale over which the strategy trades, in a single run. This simulation might take minutes to hours to run, depending on the complexity of the strategy. An experiment, on the other hand, that takes a measurement with 1 month of data needs to run for 1 month. Want 10 years of experimental data? You’ll wait 10 years.\n",
      "\n",
      "Speaker 1: Simulations may also be run multiple times on the same data set. Each run could try slight variations on the same strategy and allow the quant to choose the best one—the one with the best profit-to-risk tradeoff, for example—to trade in production. With experiments multiple runs are impossible. You can’t trade for a month, say, then “rewind” real life and trade again with a different strategy. There are effective ways to compare different strategies experimentally, but the process is orders of magnitude faster in simulation.\n",
      "\n",
      "Speaker 1: Simulations may be more precise and faster, but experiments are more accurate. Simulations might be biased (inaccurate) because of missing counterfactuals, just like prediction models. What happens, for example, when a trading strategy sends an order to an exchange? It might show up in the market, and other traders will see and respond to it. This changes future market data, which is then seen by the trading strategy and used for its decisions, and so on. Other traders’ real responses to our actions simply don’t exist in simulation.\n",
      "\n",
      "Speaker 1: MLEs use simulation, too. Engineers working on Facebook Feed use a simulator that replays logged data through the Feed code that estimates users’ responses. In “Combining online and offline tests to improve News Feed ranking,” they note that their offline simulations are biased. While the simulation results are related to real results, they don’t match exactly and the relationship between them is nontrivial. (The blog post goes on to design a model-based mapping from simulation results to experimental results.)\n",
      "\n",
      "Speaker 1: Researchers who study a field called evolutionary robotics design robot controllers—pieces of code that take in sensor information and output commands to a robot’s actuators—using algorithms inspired by evolution. The evolutionary algorithms search for controller parameters that optimize the performance of the robot as measured by a simulation. The researchers notice so often that controllers designed in simulation don’t work on real robots that they have coined a term for this effect: the reality gap.\n",
      "\n",
      "Speaker 1: In a live-streamed event, Tesla Autonomy Day, CEO Elon Musk is asked why Tesla relies so much on data collected from real drivers instead of training their autonomous driving controller via simulation. He says that they do use simulation, but that since they “don’t know what they don’t know”—and all of what they don’t know would be missing from the simulation—they invest effort and money into collecting lots of real data. In the same video, AI director Andrej Karpathy gives several examples of rare, unanticipated images from around the world that need to be interpreted by their vision system. Without appealing to real-world data, their system would never learn to deal with these images.\n",
      "\n",
      "Speaker 1: Simulation is a powerful offline design tool. Simulations can be used in the second stage of the workflow to generate estimates of business metrics. Because they tend to be biased, and you can never know exactly how, it is always necessary to test changes to your system with an experiment.\n",
      "\n",
      "Speaker 1: 1 Summary\n",
      "\n",
      "Speaker 1: 1. Experimental optimization is the process of improving an engineered system using measurement-based design decisions.\n",
      "Speaker 1: 2. Experimental methods minimize the time and risk associated with experimental measurements.\n",
      "Speaker 1: 3. Experiments are the most accurate way to measure the impact on business metrics of changes to an engineered system.\n",
      "Speaker 1: 4. Domain knowledge, prediction models, and simulation are powerful supplements to experiments but are not replacements for them.\n"
     ]
    }
   ],
   "source": [
    "parser.read()\n",
    "parsed_md = parser.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098901b",
   "metadata": {},
   "source": [
    "## 2. [Class] Set Up VibeVoice\n",
    "- Install and configure the VibeVoice package.\n",
    "- Prepare the environment for audio generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033dbf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VibeVoiceAudioGenerator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        voice: str = \"Frank\",\n",
    "        model_size: str = \"1.5b\",\n",
    "        output_dir: str = \"./content/\",\n",
    "        voices_dir: str = \"./content/voices/\",\n",
    "    ) -> None:\n",
    "        self.voice = voice\n",
    "        self.model_size = model_size\n",
    "        self.output_dir = output_dir\n",
    "        self.voices_dir = voices_dir\n",
    "\n",
    "    def _setup_model(self) -> tuple:\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        model_path: str = (\n",
    "            f\"microsoft/VibeVoice-{self.model_size}\"\n",
    "            if self.model_size == \"1.5b\"\n",
    "            else \"WestZhang/VibeVoice-Large-pt\"\n",
    "        )\n",
    "        processor = VibeVoiceProcessor.from_pretrained(model_path)\n",
    "        model = VibeVoiceForConditionalGenerationInference.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            attn_implementation=\"flash_attention_2\",\n",
    "            low_cpu_mem_usage=True,\n",
    "        )\n",
    "        model.to(torch.device(\"cuda\"))\n",
    "        model.eval()\n",
    "        model.set_ddpm_inference_steps(num_steps=10)\n",
    "        return processor, model\n",
    "\n",
    "    def _get_voice_path(self) -> str:\n",
    "        if self.voice in [\"Carter\", \"Frank\"]:\n",
    "            return os.path.join(self.voices_dir, f\"en-{self.voice}_man.wav\")\n",
    "        return os.path.join(self.voices_dir, f\"en-{self.voice}_woman.wav\")\n",
    "\n",
    "    def _process(self, processor, text: str) -> object:\n",
    "        voice_path: str = self._get_voice_path()\n",
    "        return processor(\n",
    "            text=[text],\n",
    "            voice_samples=[[voice_path]],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "\n",
    "    def _save_audio(self, outputs: object) -> str | None:\n",
    "        wav_path: str = os.path.join(self.output_dir, \"output.wav\")\n",
    "        if outputs.speech_outputs and outputs.speech_outputs[0] is not None:\n",
    "            sf.write(wav_path, outputs.speech_outputs[0].cpu().numpy(), 24000)\n",
    "            return wav_path\n",
    "        return None\n",
    "\n",
    "    def convert(self, text: str) -> str | None:\n",
    "        processor, model = self._setup_model()\n",
    "        inputs = self._process(processor, text)\n",
    "        with torch.no_grad():\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=None,\n",
    "                    cfg_scale=1.3,\n",
    "                    tokenizer=processor.tokenizer,\n",
    "                    generation_config={\"do_sample\": False},\n",
    "                    verbose=False,\n",
    "                    use_cache=True,\n",
    "                )\n",
    "        return self._save_audio(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca927f",
   "metadata": {},
   "source": [
    "## Configure VibeVoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_gen = VibeVoiceAudioGenerator(voices_dir=\"./content/drive/My Drive/Colab Notebooks/VibeVoice/voices/\")\n",
    "audio_path = audio_gen.convert(parsed_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da4515",
   "metadata": {},
   "source": [
    "## 3. Generate Audio\n",
    "- Use VibeVoice to synthesize MP3 audio from the parsed text.\n",
    "- Save the generated audio files for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52121b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_path = audio_path.replace(\".wav\", \".mp3\")\n",
    "audio = AudioSegment.from_wav(audio_path)\n",
    "audio.export(mp3_path, format=\"mp3\")\n",
    "files.download(mp3_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vibevoice-kit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
